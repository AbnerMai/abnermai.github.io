{"meta":{"title":"FlyingFish's Blog","subtitle":"FlyingFish's Blog","description":"随笔记","author":"maiyikai","url":"https://maiyikai.github.io"},"pages":[{"title":"","date":"2019-10-12T12:21:09.266Z","updated":"2019-10-12T12:21:09.266Z","comments":true,"path":"about/index.html","permalink":"https://maiyikai.github.io/about/index.html","excerpt":"","text":"关于我我是一名加入Java大家庭将近2年的小兵性格：对各种新鲜都喜欢摸清楚它的内在 近期学习目标 JVM Spring Boot+Druid配置及多数据源 线程 Spring Boot Redis … … 往期学习目标 Spring Boot-单元测试 代码重构 … …联系我暂时不支持联系我,卖个萌"}],"posts":[{"title":"LoadRunner之脚本写作","slug":"1571380748","date":"2019-10-18T14:45:00.000Z","updated":"2019-10-21T11:43:47.980Z","comments":true,"path":"2019/10/18/1571380748/","link":"","permalink":"https://maiyikai.github.io/2019/10/18/1571380748/","excerpt":"LoadRunner，是一种预测系统行为和性能的负载测试工具。通过模拟上千万用户实施并发负载及实时性能监测的方式来确认和查找问题，LoadRunner能够对整个企业架构进行测试。企业使用LoadRunner能最大限度地缩短测试时间，优化性能和加速应用系统的发布周期。LoadRunner可适用于各种体系架构的自动负载测试，能预测系统行为并评估系统性能。","text":"LoadRunner，是一种预测系统行为和性能的负载测试工具。通过模拟上千万用户实施并发负载及实时性能监测的方式来确认和查找问题，LoadRunner能够对整个企业架构进行测试。企业使用LoadRunner能最大限度地缩短测试时间，优化性能和加速应用系统的发布周期。LoadRunner可适用于各种体系架构的自动负载测试，能预测系统行为并评估系统性能。LoadRunner 更多的了解可以查看百度百科，我觉得上面讲的很全面了。本篇文章是我近段时间使用 LoadRunner 对系统进行性能测试而写，因为时间有限，所能了解的东西也有限，所以能写的也就一点点，不多… 新建脚本新建脚本，一般来说，应该都是使用的 LoadRunner 程序的脚本录制功能，这个功能是可以自动生成脚本文件的，然后我们再改改应该就可以了。但是我这边有一些情况比较特殊，不能使用录制功能，所以只能是纯手写咯。既然是要写脚本，打开程序的操作肯定是必要的吧：LoadRunner应用程序-&gt;创建/编辑脚本-&gt;新建/打开脚本 创建/编辑脚本 新建/打开脚本 脚本类型（如果是新建脚本）–默认就行 选择取消即为不录制 函数接下来我们介绍一下使用了哪一些函数，函数简单，但是还是要记一下，以为要用的东西嘛，不记得就尴尬了… 函数列表这里列出我使用到的所有函数，都是 C 语言的函数哦：123456789101112int web_add_auto_header( const char *Header, const char *Content ); int web_set_max_html_param_len( const char *length );int web_reg_save_param_ex( const char *ParamName, [const char *LB, ][const char *RB,] &lt;List of Attributes&gt;, &lt;SEARCH FILTERS&gt;,LAST ); int web_reg_find( const char *attribute_list, LAST ); int lr_start_transaction( const char *transaction_name ); int web_custom_request( const char *RequestName, &lt;List of Attributes&gt;, [EXTRARES, &lt;List of Resource Attributes&gt;,] LAST ); char *lr_eval_string( const char *instring ); int atoi( const char *string ); int lr_output_message( const char *format, exp1, exp2,...expn.); int lr_end_transaction( const char *transaction_name, int status ) ; void lr_think_time( double thinkTime); int lr_message( const char *format, exp1, exp2,...expn.); 函数介绍上面就是使用到的简单的函数，下边来对他们一一介绍，建议看官方文档咯，在程序里边的帮助就有相应的文档可以查. web_add_auto_header: Adds the specified header to all subsequent HTTP requests参数： Header: 请求头的参数，eg: Accept Content: 就是请求头参数对应的值咯，eg：如果参数是 Accept，那么值我们可以设置为：application/json就是设置 HTTP 的请求头，并将这个请求头应用到后续的请求中去–即设置一次，后续无忧。eg:web_add_auto_header(“Accept”, “application/json”); 2.web_set_max_html_param_len: Sets the maximum length of any HTML string that can be retrieved and saved as a parameter参数： length: 长度为字符形式，默认是 256 个字符就是可以检索和保存为参数的任何 HTML 字符串的最大长度。一般地，如果没用使用 HTML 请求的响应值最为参数传递给下一个 HTML 请求，那么就没必要设置这个值。 3.web_reg_save_param_ex: Registers a request to save dynamic data information to a parameter参数： ParamName: 定义参数名称 LB: 动态数据边界，左边界 RB: 动态数据边界，右边界 Attributes: DFES: 在执行所需的搜索操作之前使用的数据格式扩展的逗号分隔列表。可选的。 NOTFOUND: 在没有找到搜索项并生成空字符串时的处理选项。根据函数的不同，搜索项可以是边界，也可以是XPath。可选的。“Notfound=error”是默认值，当没有找到搜索项时，会引发错误。“Notfound=warning”不发出错误。如果没有找到搜索项，则将参数count设置为0，并继续执行脚本。如果您希望查看是否找到了字符串，但又不希望脚本失败，那么“警告”选项是最理想的。注意:如果脚本启用了Continue on Error，那么即使NOTFOUND被设置为“Error”，当搜索项没有找到时，脚本也会继续执行，但是会向扩展日志文件写入一条错误消息。可选的。 Ordinal: 表示匹配的序号位置或实例。除了传递一个数字外，还可以指定LAST。如果您指定所有参数，则参数值将保存在数组中。可选的。默认实例是1。此属性不适用于web_reg_save_param_xpath。 SaveLen:找到的值的子字符串长度，从指定的偏移量保存到参数。可选的。默认值是-1，表示保存到字符串的末尾。此属性不适用于web_reg_save_param_xpath。 SaveOffset:将找到的值的子字符串的偏移量保存到参数。偏移量必须是非负的。此属性不适用于web_reg_save_param_xpath。可选的。默认值是0。 SelectAll:指定是否保存所有找到的匹配项。如果指定了Yes，它将把匹配的值保存在数组中。可选的。默认值是No。此属性不适用于web_reg_save_param_ex。 SEARCH FILTERS: 指定缓冲区内搜索字符串的部分 使用: SEARCH_FILTERS, “RelFrameID=ALL”, “IgnoreRedirections=off”, “Scope=Body”, “ContentType=text/html”, “RequestUrl=http://mansfied/cgi-bin/echo.asp&quot;, 说明： ContentType:只搜索具有指定ContentType标头的响应。ContentType可以包含*通配符。 HeaderNames: HTTP响应头名的逗号分隔列表。只搜索指定头的值。此参数仅适用于范围为“标头”的情况。 IgnoreRedirections:如果“IgnoreRedirections=Yes”，服务器响应是重定向信息(HTTP状态码300-303,307)，响应不搜索。相反，在接收到重定向响应之后，GET请求被发送到重定向的位置，并在该位置的响应上执行搜索。默认是No。 RelFrameID: HTML页面相对于请求URL的层次结构。可能的值是ALL或一个数字。单击RelFrameID属性查看详细描述。注意:在GUI级脚本中不支持RelFrameID。 RequestURL:只搜索对该请求的响应。URL可以包含*通配符。范围:在何处搜索分隔的数据。可选的。可能的值是全部-搜索整个缓冲区、 只搜索标题、只搜索身体数据、只在Cookies中搜索；如果没有指定DFES参数，则可以使用All。如果使用Scope=Headers和HeaderNames过滤器，则只搜索指定header的值。如果没有使用HeaderNames过滤器，则搜索所有标题文本。 Scope=所有不应用于web_reg_save_param_xpath。默认值是All，除了web_reg_save_param_xpath，它的默认值是Body。就是 2 所讲，所有请求中的响应值缓存区，按照设置，将数据保存在定义的参数中，再将这个参数作为全局参数，供后续请求使用。 web_reg_find: Registers a search for a text string on an HTML page参数： attribute_list：参数列表，有好多的参数，这里先讲两个 Text: 在搜索的文本中搜索指定的内容 SaveCount: 当搜索匹配到 Text 指定的内容是，SaveCount 就会计数就是在 HTML 页面上注册对文本字串的搜索，只对靠近它的一个请求有用（自测发现） lr_start_transaction: Marks the beginning of a transaction参数： transaction_name: 即事务名称就是注册事务开启 web_custom_request: Allows you to create a custom HTTP request with any method supported by HTTP参数： ReuqestName: 注册请求的名称 Attributes: URL: 访问的请求 Method: HTTP 请求的方法 GET、POST等 EncType: 请求头中的 Content-Type Resource: 只是 URL 是否为一个资源，“1” 表示是一个资源，不会影响脚本的运行，遇到错误报“警告”；“0” 表示 URL 是关键的，不受 RTS 的影响。 Referer: 引用/参照页面 Snapshot: 快照文件 Mode: 记录级别为 HTML 或 HTTP Body: 请求使用的参数 LAST: 表示列表字段的结束用于发送 HTTP 请求的函数 lr_eval_string:Returns the string argument after evaluating embedded parameters（将 web_ref_find 计算后的参数转为一个字符串） atoi: Converts a string to an integer value（将字符串转换为整型） lr_output_message: Sends a message to log files, output windows, and other test report summaries(发送信息到日志文件、输出窗口和其他测试报告摘要) lr_end_transaction: 事务结束参数： transactions_name: 事务名称 status: LR_PASS、LR_FAIL、LR_AUTO、LR_STOP lr_think_time: 记录的思考时间，为字符串形式 eg: lr_think_time(“2”);为思考时间2s lr_message: Sends a message to log files and output windows 简单脚本编写此脚本是针对自己写的一个小服务 Demo 经行测试的，所以可能会有一些不合理的地方。 服务 Demo(JAVA)使用的是 SpringBoot 创建的一个小实例12345678910111213141516171819202122232425262728@SpringBootApplication@EnableTransactionManagement@RestController@RequestMapping(value = &quot;/Demo&quot;)public class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125; @PostMapping(value = &quot;/userInfo&quot;,produces = &quot;application/json;charset=UTF-8&quot;, consumes = &quot;application/json;charset=UTF-8&quot;) public UserInfo test(@RequestHeader(value = &quot;appName&quot;)String appName)&#123; UserInfo userInfo = new UserInfo(); userInfo.setUserName(&quot;feigntest&quot;); userInfo.setPassword(&quot;password&quot;); return userInfo; &#125; @PostMapping(value = &quot;/getUserAge&quot;/*,produces = &quot;application/json;charset=UTF-8&quot;, consumes = &quot;application/json;charset=UTF-8&quot;*/) public UserInfo getUserAge(@RequestParam (name = &quot;userName&quot;)String userName)&#123; UserInfo userInfo = new UserInfo(); userInfo.setUserName(userName); userInfo.setPassword(&quot;password&quot;); userInfo.setAge(22); return userInfo; &#125;&#125; 脚本代码此脚本包含目前在项目压测中使用的函数，每一个函数都有解释响应的理解，当然可能会有一些出入，主要是根据实际情况而定。（应该很详细了吧）脚本里边包含： 设置思考时间 定义全局应用的请求头 取请求返回的数据作为参数进行传递 发送请求的一些设置 如何判断请求是否为正确返回12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Action()&#123; //Demo lr_think_time(1); web_add_auto_header(&quot;appName&quot;, &quot;abc&quot;);//全局应用请求头--这里的请求头数据不做要求（乱写的），但是头的参数要存在，因为服务定义了 //设置可以检索和保存为参数的任何 HTML 字符串的最大长度 web_set_max_html_param_len(&quot;2048&quot;); //定义赋值参数，只能是全局的，不能定义局部，要不然编译不通过 web_reg_save_param_ex( &quot;ParamName=userName&quot;,//定义参数名称 &quot;LB/IC=\\&quot;userName\\&quot;:\\&quot;&quot;,//LB：定义左边匹配符 IC：忽略大小写 &quot;RB=\\&quot;,&quot;,//定义右边匹配符 &quot;Ordinal=1&quot;,//1:匹配的第一个数据， ALL：将所有匹配值保存为一个数组 &quot;SaveLen=-1&quot;,//不限定参数值的长度 SEARCH_FILTERS, &quot;Scope=Body&quot;,//搜索范围 &quot;RequestURL=*/Demo/userInfo*&quot;,//搜索指定的请求的响应值,如果使用完整的url作为指定请求，值为对应的web_custom_request的url的值，如果有时间戳，记得把时间戳也算上，否则会匹配不上,也可以使用通配符&apos;*&apos; LAST); //事务开启 lr_start_transaction(&quot;userInfo&quot;); //定义可以判断请求成功的验证 //函数注册一个请求，以搜索下一个操作函数(如web_url)检索到的Web页面上的文本字符串。 web_reg_find(&quot;Text=\\&quot;userName\\&quot;:\\&quot;feigntest\\&quot;&quot;, &quot;SaveCount=userInfo_count&quot;,LAST);//计算看这个事务返回的数据，判断时候存在&quot;userName&quot;: &quot;feigntest&quot;这个值，存在则userInfo_count计数+1 //请求 web_custom_request(&quot;userInfo&quot;,//请求名称--自定义即可 &quot;URL=http://10.37.1.185:8991/Demo/userInfo?time=1543200057562&quot;, //访问url &quot;Method=POST&quot;, //HTTP Method &quot;EncType=application/json&quot;,//即 指定处理请求的提交内容类型（Content-Type）,如果这个不一致，请求会报错 415 &quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;, //指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回 &quot;Referer=http://10.37.1.185:8991/&quot;, &quot;Snapshot=t13.inf&quot;, &quot;Mode=HTML&quot;, &quot;Body=&quot;, //不需要参数 LAST); //判断是否正确结束事务 if( atoi(lr_eval_string(&quot;&#123;userInfo_count&#125;&quot;)) &gt; 0) &#123; lr_end_transaction(&quot;userInfo&quot;, LR_PASS); &#125; else &#123; lr_end_transaction(&quot;userInfo&quot;, LR_FAIL); &#125; //事务开启 lr_start_transaction(&quot;getUserAge&quot;); //定义可以判断请求成功的验证 web_reg_find(&quot;Text=\\&quot;age\\&quot;:22&quot;, &quot;SaveCount=getUserAge_count&quot;,LAST);//计算看这个事务返回的数据，判断时候存在&quot;userName&quot;: &quot;feigntest&quot;这个值，存在则userInfo_count计数+1 //请求 web_custom_request(&quot;getUserAge&quot;,//请求名称--自定义即可 &quot;URL=http://10.37.1.185:8991/Demo/getUserAge?time=1543200057562&quot;, //访问url &quot;Method=POST&quot;, //HTTP Method //&quot;EncType=application/json&quot;,//这个请求不能加 RequestHeader--ContentType，不然会让接口报400错误----如果一定要使用这个参数，那么我们的请求参数就不能放在Body定义，直接拼接到url中。。实际要根据接口定义来使用 &quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;, //指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回 &quot;Referer=http://10.37.1.185:8991/&quot;, &quot;Snapshot=t13.inf&quot;, &quot;Mode=HTML&quot;, &quot;Body=userName=&#123;userName&#125;&quot;, //使用上一个请求所得的参数值赋值使用,,也可以直接拼接到url上 LAST); //判断是否正确结束事务 if( atoi(lr_eval_string(&quot;&#123;userInfo_count&#125;&quot;)) &gt; 0) &#123; lr_end_transaction(&quot;getUserAge&quot;, LR_PASS);//正常返回状态为Pass &#125; else &#123; lr_end_transaction(&quot;getUserAge&quot;, LR_FAIL);//错误返回状态为Fail &#125; return 0;&#125; 测试结果的查看和日志选项脚本编写完毕之后，要进行编译测试，确认脚本正常执行才能用于进行性能测试工作。接下来看看日志中如何确认脚本是否正常吧… 测试结果的查看（标准日志） 根据图片上的日志情况就可以反应出当前脚本的运行情况 debug 调式正所谓“理想很丰满，显示很骨感”。并不是所有的脚本编写完成之后都能正常的运行，而根据 1 选项的日志却看不出来脚本的实际情况，那怎么办呢？认命？不存在的…可以先通过 debug 调式看看能不能找到问题…那么如何 debug 呢？这里要使用到两个按键 F5 和 F9，F5 就是运行啦，F9 就是 debug 断点设置和取消70% 的错误都是因为粗心大意而出现的，所以可以通过这种方式查看一下，是不是参数或者是语法导致的错误… 日志查看如果单纯的进行 debug 调式都不能解决问题，那就 只能通过高级日志的查看看看咯…它的位置如下图: 日志打印出来的就比标准日志要多得多，但是在性能测试阶段，建议使用 “仅在出错时返送消息” 或者 “始终发送消息–&gt;标准日志” ，不然可能日志可能会将你的压力机磁盘写满，导致你后续无法继续工作。也建议偶尔自己去删除打印出来的日志，让压力机减负运行嘛。 参数设置上边的例子没有用到参数列表，所以现在介绍参数列表的使用（例子根据上边的例子进行改造），所以下边开始对如何设置参数进行叙述。这里进行简单的例子：我们将上述例子中的语句稍微修改一下： web_add_auto_header(&quot;appName&quot;, &quot;abc&quot;); 修改为 web_add_auto_header(&quot;appName&quot;, &quot;{appNameArg}&quot;); ，此处的 {appNameArg} 为我们定义的参数，中括号不能落下，否则就不是获取参数咯…如果参数列表中没有定义 ‘appNameArg’ 这个参数，那么在脚本中的显示为绿色，如下图： 这里要切记， 使用函数 ‘web_reg_save_param_ex’ 定义的参数，他就是绿色的哦，所以看到绿色参数时要确认是通过 ‘web_reg_save_param_ex’ 函数获取的，还是通过参数列表获取的，不要慌… 接下来看看如果使用参数列表： 打开参数列表定义工具 参数定义和选项介绍新建参数：点击“新建”，输入参数名称，回车即可参数类型：选择对应的参数名称设置参数类型，目前使用到的有 File、Random Number。File 即为文件，以.dat为后缀；Random Number 即为随机数。接下来展示两张图作为参考： 参数值的设置：按编号：即为按列，其实列序号为 1 ，意思时这个参数它对应的时哪个列按名称：即为列名列分割符：Comma(逗号)、Tab(Tab空白)、Space（空格）选择下一行与更新值时间搭配： Sequential(连续的)、Random(随机的)、Unique(唯一的)： Each Iteration：迭代使用，执行一遍脚本用一个值，且当前进程内不会发生改变 Each occurrence：当前当次使用，执行一遍脚本，每次获取到的参数的值都是按顺序往下取值 Once：只使用一次，不重复利用 参数值的设置：从 最小值-最大值 之前取值，即为从 1-100 之间随机取值 参数使用定义成功之后，函数 web_reg_save_param_ex 参数定义部分显示为粉红色，如图： 至此，LoadRunner 简单脚本的编写已经完成了，如遇有疑问或文章有问题，欢迎反馈… 参考文献 百度百科：https://baike.baidu.com/item/loadrunner/1926633?fr=aladdin LoadRunner-常用的函数：https://www.cnblogs.com/zhuzhubaoya/p/9084163.html","categories":[{"name":"LoadRunner","slug":"LoadRunner","permalink":"https://maiyikai.github.io/categories/LoadRunner/"}],"tags":[{"name":"LoadRunner","slug":"LoadRunner","permalink":"https://maiyikai.github.io/tags/LoadRunner/"},{"name":"Test","slug":"Test","permalink":"https://maiyikai.github.io/tags/Test/"},{"name":"script","slug":"script","permalink":"https://maiyikai.github.io/tags/script/"}]},{"title":"错误记录-SpringBoot 之 POI 实现 Excel 操作","slug":"1568191417","date":"2019-09-11T16:30:00.000Z","updated":"2019-10-12T12:21:09.265Z","comments":true,"path":"2019/09/12/1568191417/","link":"","permalink":"https://maiyikai.github.io/2019/09/12/1568191417/","excerpt":"在项目中，对 Excel 的操作，我们一般都会使用 POI 这个工具包。而这个工具包也在不断的优化，所以会存在很多的版本，那么在 MAVEN 项目中，经常会引入不同的依赖 ，所以会在不经意间引入不同版本的依赖，导致正常运行的项目突然之间抛出很多没见过的异常。而这篇文章内容就是根据所遇而写的…","text":"在项目中，对 Excel 的操作，我们一般都会使用 POI 这个工具包。而这个工具包也在不断的优化，所以会存在很多的版本，那么在 MAVEN 项目中，经常会引入不同的依赖 ，所以会在不经意间引入不同版本的依赖，导致正常运行的项目突然之间抛出很多没见过的异常。而这篇文章内容就是根据所遇而写的… POI 依赖引入我们经常会使用 POI 对数据表的导入导出进行操作，而这个工具包无疑是最合适的。每次的更新都能提供更好的性能。所使用的的依赖如下：1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.10-FINAL&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.10-FINAL&lt;/version&gt;&lt;/dependency&gt; 多版本 Excel 工具类实例化当然我使用的并不是最新的内容。很早之前我们使用 POI 工具包实例化针对于不同版本的 Excel 的对象，如：123456789//针对于03版本的Excel，实例化对象POIFSFileSystem pfs = new POIFSFileSystem(new FileInputStream(file)); HSSFWorkbook hwb = new HSSFWorkbook(pfs);//针对于07版本的Excel，实例化对象XSSFWorkbook xw = new XSSFWorkbook(file);//兼容多个Excel版本的实例化对象，最方便，可以完成多个后缀的读写 .xls || .xlsxWorkbook workbook = WorkbookFactory.create(new FileInputStream(file)); 项目中使用：1SXSSFWorkbook wb = new SXSSFWorkbook(100); 无疑，我一般使用的肯定是第三种我们先看看报了什么错… 报错信息测试环境：1234Caused by: java.lang.RuntimeException: java.io.IOException: No such file or directory at org.apache.poi.xssf.streaming.SXSSFWorkbook.createAndRegisterSXSSFSheet(SXSSFWorkbook.java:640) at org.apache.poi.xssf.streaming.SXSSFWorkbook.createSheet(SXSSFWorkbook.java:657) at org.apache.poi.xssf.streaming.SXSSFWorkbook.createSheet(SXSSFWorkbook.java:71) 没有这个文件或目录？不可能，这个目录是存在的… 开发及本地：1234567Caused by: java.io.IOException: Zip bomb detected! The file would exceed the max. ratio of compressed file size to the size of the expanded data. This may indicate that the file is used to inflate memory usage and thus could pose a security risk. You can adjust this limit via ZipSecureFile.setMinInflateRatio() if you need to work with files which exceed this limit. Counter: 172032, cis.counter: 1716, ratio: 0.009974888392857142Limits: MIN_INFLATE_RATIO: 0.01 at org.apache.poi.openxml4j.util.ZipSecureFile$ThresholdInputStream.advance(ZipSecureFile.java:258) at org.apache.poi.openxml4j.util.ZipSecureFile$ThresholdInputStream.read(ZipSecureFile.java:215) at java.io.FilterInputStream.read(FilterInputStream.java:107) at org.apache.poi.xssf.streaming.SXSSFWorkbook.copyStream(SXSSFWorkbook.java:386) at org.apache.poi.xssf.streaming.SXSSFWorkbook.injectData(SXSSFWorkbook.java:368) at org.apache.poi.xssf.streaming.SXSSFWorkbook.write(SXSSFWorkbook.java:947) 压缩比？没用到压缩这个玩意儿啊… 内心独白咦！！！同样的代码，不同的错误信息？怎么搞得？难道是测试环境没给写的权限？不对啊，之前都是正常的啊，这个代码大半年都没动了，难道是有人把权限给改动了？会不会是我？这段时间我一直都是在弄 linux 相关的学习，会不会给误点了？先不管了，先看看本地为什么会报错吧… 错误排查经过一番的心理斗争，还是默默的去找原因，经过我代码排查，找到了是在写流的时候报的错，代码：1234// 输出流 FileOutputStream os = new FileOutputStream(&quot;test.xlsx&quot;);//excel---这个地方报错了workbook.write(os); 奇怪了，怀疑可能是包的问题，先查查用了哪些包吧，经过查找，发现在 pom.xml 中只引用了 3.10-FINAL 版本的 POI 包。奇怪了，找到实例化的工厂对象，看看到哪个地方去了。通过实例化的方法，去查，发现是进入了 3.10-FINAL 版本的。 还是采用查找类路径的方法吧，这么一查，发现还有一个 3.14 版本的 POI。好吧，我在两个版本的构造方法都打上断点，很神奇的发现，它居然跳到了 3.14 版本的类中，实例化了 3.14 版本的 SXSSFWorkbook 实例。 神奇了，编程工具中的 依赖结构查询 没发现有 3.14 版本的，为啥就跑过去了？查找 pom.xml 看是不是我无意中弄进去了，然而通过工程的 pom.xml 并没有发现。所以只能使用最笨的方式了，一个一个依赖的找，最终发现是我在写单元测试的时候引入一个包导致的：123456&lt;dependency&gt; &lt;groupId&gt;org.dbunit&lt;/groupId&gt; &lt;artifactId&gt;dbunit&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 进入这个依赖发现这里边居然有依赖 POI 相关的包，就是 3.14 版本的：123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.14&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.14&lt;/version&gt; &lt;/dependency&gt; 问题解决额好吧，它自己引入的，那我引入 dbunit 这个依赖的时候就去掉就是了：12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.dbunit&lt;/groupId&gt; &lt;artifactId&gt;dbunit&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 打包…再测试，正常了…上测试环境，居然也正常了… 总结在开发的时候，总会因为需要而引入不同的依赖，而每次引入依赖的时候，没有仔细的去检查这个依赖中时候存在和当前项目所使用的依赖有冲突的依赖版本，导致了因版本冲突而使代码抛出异常。 参考1.我在CSND写的DEMO：https://blog.csdn.net/maiyikai/article/details/70331798","categories":[{"name":"error","slug":"error","permalink":"https://maiyikai.github.io/categories/error/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/tags/SpringBoot/"},{"name":"POI","slug":"POI","permalink":"https://maiyikai.github.io/tags/POI/"},{"name":"Excel","slug":"Excel","permalink":"https://maiyikai.github.io/tags/Excel/"}]},{"title":"MyBatis 之 <![CDATA[ ]]>","slug":"1564117346","date":"2019-07-26T10:00:00.000Z","updated":"2019-10-12T12:21:09.265Z","comments":true,"path":"2019/07/26/1564117346/","link":"","permalink":"https://maiyikai.github.io/2019/07/26/1564117346/","excerpt":"在 MyBatis 中，我们都知道 mapper.xml 是使用了 XML 的语法，所以会出现有一些特殊的字符不能直接被转义，在编译解析时，会导致编译出错。例如：’&lt;’ 和 ‘&amp;’ 字符在 XML 元素中都是非法的","text":"在 MyBatis 中，我们都知道 mapper.xml 是使用了 XML 的语法，所以会出现有一些特殊的字符不能直接被转义，在编译解析时，会导致编译出错。例如：’&lt;’ 和 ‘&amp;’ 字符在 XML 元素中都是非法的 疑问？ &lt;![CDATA[ ]]&gt; 是什么东东？ 在 MyBatis 中使用 &lt;![CDATA[ ]]&gt; 不能解决的问题？ 如何解决问题？ &lt;![CDATA[ ]]&gt; 是什么东东？术语 CDATA 是不应该由 XML 解析器解析的文本数据。像 “&lt;” 和 “&amp;” 字符在 XML 元素中都是非法的。“&lt;” 会产生错误，因为解析器会把该字符解释为新元素的开始。“&amp;” 会产生错误，因为解析器会把该字符解释为字符实体的开始。某些文本，MyBatis，判断大小：”SELECT * FROM USER U WHERE U.AGE &lt; 20 “。为了避免错误，可以将脚本代码定义为 CDATA。 CDATA 部分中的所有内容都会被解析器忽略。CDATA 部分由 “&lt;![CDATA[“ 开始，由 “]]&gt;” 结束：12345&lt;SELECT id=&quot;queryUser&quot; resultType=&quot;com.myk.entity.User&quot;&gt;&lt;![CDATA[SELECT * FROM USER U WHERE U.AGE &lt; 20 ]]&gt;&lt;/SELECT&gt; 在上面的实例中，解析器会忽略 CDATA 部分中的所有内容。那么 &lt;![CDATA[ ]]&gt; 部分中的内容将被视为是一个文本数据。 关于 CDATA 部分的注释：CDATA 部分不能包含字符串 “]]&gt;”。也不允许嵌套的 CDATA 部分。标记 CDATA 部分结尾的 “]]&gt;” 不能包含空格或换行。 在 MyBatis 中使用 &lt;![CDATA[ ]]&gt; 不能解决的问题根据上边的解释，应该都知道使用 &lt;![CDATA[ ]]&gt; 会有怎样的效果，那为什么还有不能解决的问题呢？都知道 MyBatis 中有很多的运算标签，如 &lt;if&gt;&lt;/if&gt;、&lt;foreach&gt;&lt;/foreach&gt;、&lt;where&gt;&lt;/where&gt;、&lt;choose&gt;&lt;/choose&gt; 等标签。这里既然提到了这些标签，那么就说明 &lt;![CDATA[]]&gt; 与这些标签一起使用，在执行的时候将会出现问题。，这是为什么呢？因为在 MyBatis 中，解析器解析到这些标签的时候，会单独进行运算封装。而当这些标签被 &lt;![CDATA[ ]]&gt; 标记为文本内容之后，不会被解析器解析，而是将 &lt;![CDATA[ ]]&gt; 标记的内容当成是一条完整的 SQL 语句，进行执行操作，而这条被标记的 SQL 很明显就是有语法问题的，所以执行就是抛异常。如：12345678910&lt;SELECT id=&quot;queryUser&quot; resultType=&quot;com.myk.entity.User&quot;&gt;&lt;![CDATA[SELECT * FROM USER U WHERE U.AGE &amp;lt; 20 ANDU.userId IN&lt;foreach collection=&quot;userIdList&quot; item=&quot;userId&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt;#&#123;userId&#125;&lt;/foreach&gt; ]]&gt;&lt;/SELECT&gt; 以上代码会出现两个问题： SQL 中的 &amp;lt; 不会被转义为 ‘&lt;’ 符号 SQl 中的 &lt;foreach&gt;&lt;/foreach&gt; 标签不会被解析执行，而是当成文本内容 SQL 被解析之后是这样的：SELECT * FROM USER U WHERE U.AGE &amp;lt; 20 AND U.userId IN &lt;foreach collection=&quot;userIdList&quot; item=&quot;userId&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #{userId} &lt;/foreach&gt; 解决 MyBatis 中使用 &lt;![CDATA[ ]]&gt; 的问题目前我有两种想法可以使用 精准定位什么叫精准定位呢？即哪里需要，就标记哪里,最大限度的减少被 &lt;![CDATA[ ]]&gt; 标记的范围，减少出错的可能。如：12345678910&lt;SELECT id=&quot;queryUser&quot; resultType=&quot;com.myk.entity.User&quot;&gt;&lt;![CDATA[SELECT * FROM USER U WHERE U.AGE &lt; 20 ]]&gt;ANDU.userId IN&lt;foreach collection=&quot;userIdList&quot; item=&quot;userId&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt;#&#123;userId&#125;&lt;/foreach&gt; &lt;/SELECT&gt; 最后解析出来的 SQL ：SELECT * FROM USER U WHERE U.AGE &lt; 20 AND userId IN （&#39;&#39;） SQL全包裹全包裹，顾名思义就是 &lt;![CDATA[ ]]&gt; 标记整条 SQL ，如果必须使用这种方式，那么 SQL 中就不能出现 MyBatis 的运算标签，如：1234567&lt;SELECT id=&quot;queryUser&quot; resultType=&quot;com.myk.entity.User&quot;&gt;&lt;![CDATA[SELECT * FROM USER U WHERE U.AGE &lt; 20 ANDU.userId = #&#123;userId&#125; ]]&gt;&lt;/SELECT&gt; 最后解析出来的 SQL ：SELECT * FROM USER U WHERE U.AGE &lt; 20 AND U.userId = #{userId}","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://maiyikai.github.io/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://maiyikai.github.io/tags/MyBatis/"}]},{"title":"正则表达式的简单使用","slug":"1563873556","date":"2019-07-23T15:00:00.000Z","updated":"2019-10-12T12:21:09.265Z","comments":true,"path":"2019/07/23/1563873556/","link":"","permalink":"https://maiyikai.github.io/2019/07/23/1563873556/","excerpt":"正则表达式，又称规则表达式（Regular Express【代码中常见：regex、regexp、RE】）。 正则表达式在处理文本替换、数据匹配、数据筛选等时候可以提高工作效率；例如给一个100M的文档给你，让查询某种格式的内容时，不需要用“人工智障”的方式死盯着，直接通过正则匹配查询，即可精确的查找想要找到的内容。","text":"正则表达式，又称规则表达式（Regular Express【代码中常见：regex、regexp、RE】）。 正则表达式在处理文本替换、数据匹配、数据筛选等时候可以提高工作效率；例如给一个100M的文档给你，让查询某种格式的内容时，不需要用“人工智障”的方式死盯着，直接通过正则匹配查询，即可精确的查找想要找到的内容。 简介正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定的字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。 目的 给定的字符串是否符合正则表达式的过滤逻辑 可以通过正则表达式，从字符串中获取我们想要的特定部分 特点 灵活性、逻辑性和功能性强 可以迅速地用极简单的方式达到字符串的复杂控制 元字符 字符 描述 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，’n’ 匹配字符 “n”。’\\n’ 匹配一个换行符。序列 ‘\\‘ 匹配 “\\” 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\\n’ 或 ‘\\r’ 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\\n’ 或 ‘\\r’ 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo 能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。 {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。 . 匹配除换行符（\\n、\\r）之外的任何单个字符。要匹配包括 ‘\\n’ 在内的任何字符，请使用像”(.&#124;\\n)”的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ‘(‘ 或 ‘)‘。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 (&#124;) 来组合一个模式的各个部分是很有用。例如， ‘industr(?:y&#124;ies) 就是一个比 ‘industry&#124;industries’ 更简略的表达式。 (?=pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，”Windows(?=95&#124;98&#124;NT&#124;2000)”能匹配”Windows2000”中的”Windows”，但不能匹配”Windows3.1”中的”Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如”Windows(?!95&#124;98&#124;NT&#124;2000)”能匹配”Windows3.1”中的”Windows”，但不能匹配”Windows2000”中的”Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?&lt;=pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，”(?&lt;=95&#124;98&#124;NT&#124;2000)Windows”能匹配”2000Windows”中的”Windows”，但不能匹配”3.1Windows”中的”Windows”。 (?&lt;!pattern) 反向否定预查，与正向否定预查类似，只是方向相反。例如”(?&lt;!95&#124;98&#124;NT&#124;2000)Windows”能匹配”3.1Windows”中的”Windows”，但不能匹配”2000Windows”中的”Windows”。 x&#124;y 匹配 x 或 y。例如，’z&#124;food’ 能匹配 “z” 或 “food”。’(z&#124;f)ood’ 则匹配 “zood” 或 “food”。 [xyz] 字符集合。匹配所包含的任意一个字符。例如， ‘[abc]’ 可以匹配 “plain” 中的 ‘a’。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如， ‘[^abc]’ 可以匹配 “plain” 中的’p’、’l’、’i’、’n’。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，’[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，’[^a-z]’ 可以匹配任何不在 ‘a’ 到 ‘z’ 范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \\B 匹配非单词边界。’er\\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 \\cx 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \\d 匹配一个数字字符。等价于 [0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于 \\x0c 和 \\cL。 \\n 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w 匹配字母、数字、下划线。等价于’[A-Za-z0-9_]’。 \\W 匹配非字母、数字、下划线。等价于 ‘[^A-Za-z0-9_]’。 \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，’\\x41’ 匹配 “A”。’\\x041’ 则等价于 ‘\\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。 \\num 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，’(.)\\1’ 匹配两个连续的相同字符。 \\n 标识一个八进制转义值或一个向后引用。如果 \\n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \\nm 标识一个八进制转义值或一个向后引用。如果 \\nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \\nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \\nm 将匹配八进制转义值 nm。 \\nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。 运算符优先级 运算符 描述 \\ 转义符 (), (?:), (?=), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） &#124; 替换，”或”操作字符具有高于替换运算符的优先级，使得”m&#124;food”匹配”m”或”food”。若要匹配”mood”或”food”，请使用括号创建子表达式，从而产生”(m&#124;f)ood”。 规则 数字 数字：^[0-9]*$ n位的数字：^\\d{n}$ 至少n位的数字：^\\d{n,}$ m-n位的数字：^\\d{m,n}$ 零和非零开头的数字：^(0|[1-9][0-9]*)$ 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$ 带1-2位小数的正数或负数：^(-)?\\d+(.\\d{1,2})$ 正数、负数、和小数：^(-|+)?\\d+(.\\d+)?$ 有两位小数的正实数：^[0-9]+(.[0-9]{2})?$ 有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$ 非零的正整数：^[1-9]\\d$ 或 ^([1-9][0-9]){1,3}$ 或 ^+?[1-9][0-9]*$ 非零的负整数：^-[1-9][]0-9”$ 或 ^-[1-9]\\d$ 非负整数：^\\d+$ 或 ^[1-9]\\d*|0$ 非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$ 非负浮点数：^\\d+(.\\d+)?$ 或 ^[1-9]\\d.\\d|0.\\d[1-9]\\d|0?.0+|0$ 非正浮点数：^((-\\d+(.\\d+)?)|(0+(.0+)?))$ 或 ^(-([1-9]\\d.\\d|0.\\d[1-9]\\d))|0?.0+|0$ 正浮点数：^[1-9]\\d.\\d|0.\\d[1-9]\\d$ 或 ^(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9]))$ 负浮点数：^-([1-9]\\d.\\d|0.\\d[1-9]\\d)$ 或 ^(-(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9])))$ 浮点数：^(-?\\d+)(.\\d+)?$ 或 ^-?([1-9]\\d.\\d|0.\\d[1-9]\\d|0?.0+|0)$ 字符 汉字：^[\\u4e00-\\u9fa5]{0,}$ 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$ 长度为3-20的所有字符：^.{3,20}$ 由26个英文字母组成的字符串：^[A-Za-z]+$ 由26个大写英文字母组成的字符串：^[A-Z]+$ 由26个小写英文字母组成的字符串：^[a-z]+$ 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w{3,20}$ 中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$ 中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$ 可以输入含有^%&amp;’,;=?$\\”等字符：[^%&amp;’,;=?$\\x22]+ 禁止输入含有~的字符：[^~\\x22]+ 特殊需求 Email地址：^\\w+([-+.]\\w+)@\\w+([-.]\\w+).\\w+([-.]\\w+)*$ 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? InternetURL：[a-zA-z]+://[^\\s] 或 ^http://([\\w-]+.)+[\\w-]+(/[\\w-./?%&amp;=])?$ 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d{8}$ 电话号码(“XXX-XXXXXXX”、”XXXX-XXXXXXXX”、”XXX-XXXXXXX”、”XXX-XXXXXXXX”、”XXXXXXX”和”XXXXXXXX)：^((\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$ 国内电话号码(0511-4405222、021-87888822)：\\d{3}-\\d{8}|\\d{4}-\\d{7} 电话号码正则表达式（支持手机号码，3-4位区号，7-8位直播号码，1－4位分机号）: ((\\d{11})|^((\\d{7,8})|(\\d{4}|\\d{3})-(\\d{7,8})|(\\d{4}|\\d{3})-(\\d{7,8})-(\\d{4}|\\d{3}|\\d{2}|\\d{1})|(\\d{7,8})-(\\d{4}|\\d{3}|\\d{2}|\\d{1}))$) 身份证号(15位、18位数字)，最后一位是校验位，可能为数字或字符X：(^\\d{15}$)|(^\\d{18}$)|(^\\d{17}(\\d|X|x)$) 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\\w{5,17}$ 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在 8-10 之间)：^(?=.\\d)(?=.[a-z])(?=.*[A-Z])[a-zA-Z0-9]{8,10}$ 强密码(必须包含大小写字母和数字的组合，可以使用特殊字符，长度在8-10之间)：^(?=.\\d)(?=.[a-z])(?=.*[A-Z]).{8,10}$ 日期格式：^\\d{4}-\\d{1,2}-\\d{1,2} 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$ 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式： 有四种钱的表示形式我们可以接受:”10000.00” 和 “10,000.00”, 和没有 “分” 的 “10000” 和 “10,000”：^[1-9][0-9]*$ 这表示任意一个不以0开头的数字,但是,这也意味着一个字符”0”不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧。下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 必须说明的是,小数点后面至少应该有1位数,所以”10.”是不通过的,但是 “10” 和 “10.2” 是通过的：^[0-9]+(.[0-9]{2})?$ 这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$ 这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$ 1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$ 备注：这就是最终结果了,别忘了”+”可以用”*”替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$ 中文字符的正则表达式：[\\u4e00-\\u9fa5] 双字节字符：[^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1)) 空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行) HTML标记的正则表达式：&lt;(\\S?)[^&gt;]&gt;.?|&lt;.? /&gt; ( 首尾空白字符的正则表达式：^\\s|\\s$或(^\\s)|(\\s$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式) 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始) 中国邮政编码：[1-9]\\d{5}(?!\\d) (中国邮政编码为6位数字) IP地址：((?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)) 查询替换（例子仅限于此处测试使用） eg1: 去除字符串中的某些内容，其余项保留 字符串：abc123ijn@qq.com 要求： 去除邮箱中的“123”内容 查询正则： ([a-z|A-Z]{3})(\\d{3})([a-z|A-Z]{3})(@qq.com) 替换正则： $1$3$4 结果： abcijn@qq.com 解析：使用”()”将字符串“abc123ijn@qq.com”分为4个部分，“$1”表示取的是被分割的字符串的第1部分；类似于一个将字符串分割成一个数组，“1 | 2 | 3 | …”分别代表的是数组的下标，“$1”即为取第一个下标的数据。 eg2: 在字符串前添加指定字符，其他的内容不变 字符串：abc123ijn@qq.com 要求：在字符串“abc”和“123”之间添加符号“#￥%” 查询正则： ([a-z|A-Z]{3})(\\d{3})([a-z|A-Z]{3})(@qq.com) 替换正则： $1#￥%$2$3$4 结果：abc#￥%123ijn@qq.com 解析：同上 eg3: 替换字符串中的某些内容 字符串：abc123ijn@qq.com 要求：将字符串“123”，替换为“iloveu” 查询正则： ([a-z|A-Z]{3})(\\d{3})([a-z|A-Z]{3})(@qq.com) 替换正则： $1iloveu$3$4 结果：abciloveuijn@qq.com 解析：同上 参考内容 摘抄自：https://www.runoob.com/regexp/regexp-tutorial.html","categories":[{"name":"regex","slug":"regex","permalink":"https://maiyikai.github.io/categories/regex/"}],"tags":[{"name":"regex","slug":"regex","permalink":"https://maiyikai.github.io/tags/regex/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://maiyikai.github.io/tags/正则表达式/"}]},{"title":"LoadRunner使用google浏览器脚本录制","slug":"1558665386","date":"2019-05-24T10:00:00.000Z","updated":"2019-10-12T12:21:09.265Z","comments":true,"path":"2019/05/24/1558665386/","link":"","permalink":"https://maiyikai.github.io/2019/05/24/1558665386/","excerpt":"莫名其妙的接到压力测试的任务 工具：LoadRunner v.11、Google Chrome","text":"莫名其妙的接到压力测试的任务 工具：LoadRunner v.11、Google Chrome其实LoadRunner支持多个浏览器的，ie浏览器是最好的选择，奈何项目不支持ie，而使用Google Chrome，LoadRunner又不能将它直接打开录制，所以只能是找找找资料了，功夫不负有心人，网上很多都是“渣”，不可用。 浏览器LoadRunner支持的浏览器： 8.0 最高ie6 8.1 最高ie6 9.0 最高ie7 9.5 最高ie8 11.0 最高ie9( win7 32位+LR11+IE10可用，但win7 64位+LR11+IE10不可用，降至IE9可用)，支持firefox3.6、24.0 12.0 支持IE11 LoadRunner 打开LoadRunner 创建脚本，点击上图“创建/编辑脚本” 进入到开始录制界面 设置 选择要录制的程序–&gt;到LoadRunner的安装路径下查找：C:\\Program Files (x86)\\HP\\LoadRunner\\bin文件名为“wplus_init_wsock”的程序 2. 输入要录制的URL(隐私保护，这是假的): http://www.baidu.com 3. 点击下方选项按钮 4. 创建条目 5. 更新之后确认即可 6. 返回到第一步，先不要录制，需要等到浏览器设置好之后才能录制 Google Chrome设置 打开浏览器，进入设置，选择系统设置，再选择打开代理设置 设置代理 开始录制 进入LoadRunner,开始录制 打开浏览器，在地址栏输入你要录制的服务器地址 录制完成 到这里，就基本结束了 参考资料 Loadrunner如何使用谷歌浏览器录制脚本https://blog.csdn.net/qq_43485197/article/details/83652797","categories":[{"name":"LoadRunner","slug":"LoadRunner","permalink":"https://maiyikai.github.io/categories/LoadRunner/"}],"tags":[{"name":"LoadRunner","slug":"LoadRunner","permalink":"https://maiyikai.github.io/tags/LoadRunner/"},{"name":"Test","slug":"Test","permalink":"https://maiyikai.github.io/tags/Test/"}]},{"title":"CenterOS服务器搭建--网络配置","slug":"1558423260","date":"2019-05-21T15:00:00.000Z","updated":"2019-10-12T12:21:09.264Z","comments":true,"path":"2019/05/21/1558423260/","link":"","permalink":"https://maiyikai.github.io/2019/05/21/1558423260/","excerpt":"在虚拟机中安装了LINUX系统，在例子中全部使用的是CenterOS，版本是8.3。 系统版本不一样，会导致有部分命令是改变的，例如这个版本查看ip地址的命令是：ip add/addr","text":"在虚拟机中安装了LINUX系统，在例子中全部使用的是CenterOS，版本是8.3。 系统版本不一样，会导致有部分命令是改变的，例如这个版本查看ip地址的命令是：ip add/addr 查看本机ip地址输入命令： ip addr下图教你如何查看服务器的ip,如果一开始没有配置，或者没有使用桥接联网的话，一般都是“127.0.0.1” 网络配置文件网卡文件地址路径：/etc/sysconfig/network-scripts/ 查看一下目录下的文件/目录：ls -al 名称：通过上图可以看到配置文件名称名称，一般都是前缀为“ifcfg-”,后缀为网卡名称”eth0” 使用vi文本编辑器编辑文件输入命令vi ifcfg-eth0，查看文件默认的内容： 123456789101112131415TYPE=Ethernet # 网卡类型：为以太网PROXY_METHOD=none # 代理方式：关闭状态BROWSER_ONLY=no # 只是浏览器：否BOOTPROTO=dhcp # 网卡的引导协议：DHCP[中文名称: 动态主机配置协议], static :静态 none:不指定DEFROUTE=yes # 默认路由：是, 不明白的可以百度关键词 `默认路由` IPV4_FAILURE_FATAL=no # 是不开启IPV4致命错误检测：否IPV6INIT=yes # IPV6是否自动初始化: 是[不会有任何影响, 现在还没用到IPV6]IPV6_AUTOCONF=yes # IPV6是否自动配置：是[不会有任何影响, 现在还没用到IPV6]IPV6_DEFROUTE=yes # IPV6是否可以为默认路由：是[不会有任何影响, 现在还没用到IPV6]IPV6_FAILURE_FATAL=no # 是不开启IPV6致命错误检测：否IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地址生成模型：stable-privacy [这只一种生成IPV6的策略]NAME=eth0 # 网卡物理设备名称UUID=f47bde51-fa78-4f79-b68f-d5dd90cfc698 # 通用唯一识别码, 每一个网卡都会有, 不能重复, 否两台linux只有一台网卡可用DEVICE=eth0 # 网卡设备名称, 必须和 `NAME` 值一样ONBOOT=no # 是否开机启动， 要想网卡开机就启动或通过 `systemctl restart network`控制网卡,必须设置为 `yes` 静态网络要配置 规划服务器ip，配置自己的局域网，需要改动几个属性的值： 敲键盘按键”Insert”，进入编辑状态 找到合适的位置进行编辑 退出：先按“Esc”键，然后输入:wq，保存并退出， 或:q!，强制退出并不保存。 1234567BOOTPROTO=staticONBOOT=yesIPADDR=192.168.3.190NETMASK=255.255.255.0GATEWAY=192.168.3.1DNS1=114.114.114.114DNS2=8.8.8.8 注意： 其他不明白的不要动它 网管和ip段要与宿主机一致，否则不能通过宿主机访问服务器 重新启动网络重新启动网络，使其生效：service network restart 验证网络： 参考资料 Linux IP和网关配置 https://www.cnblogs.com/linyfeng/p/7534677.html linux_下IP、网关、DNS地址配置 https://www.cnblogs.com/xuzhiwei/p/3560553.html","categories":[{"name":"CenterOS","slug":"CenterOS","permalink":"https://maiyikai.github.io/categories/CenterOS/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://maiyikai.github.io/tags/LINUX/"},{"name":"Network","slug":"Network","permalink":"https://maiyikai.github.io/tags/Network/"},{"name":"CenterOS","slug":"CenterOS","permalink":"https://maiyikai.github.io/tags/CenterOS/"}]},{"title":"Spring Boot配备多数据源","slug":"1554706715","date":"2019-04-08T15:00:00.000Z","updated":"2019-10-12T12:21:09.264Z","comments":true,"path":"2019/04/08/1554706715/","link":"","permalink":"https://maiyikai.github.io/2019/04/08/1554706715/","excerpt":"一般情况下，我们一个服务最多使用一个数据源，并且拥有一个连接池； 但是不能避免的特殊情况，会使用多个库（不包括分库操作），所以就要配备多个指定的数据源，分别对不同的库进行操作","text":"一般情况下，我们一个服务最多使用一个数据源，并且拥有一个连接池； 但是不能避免的特殊情况，会使用多个库（不包括分库操作），所以就要配备多个指定的数据源，分别对不同的库进行操作 接下来就开始写代码吧！ 数据库准备分别建立两个不同的库(名字任意，本例子使用：dynamic1和dynamic2)，在其中建立不同的表，当然如果你懒得话，可以和我一样，复制粘贴，改个名字就行（针对库），你会发现省了很多事… O(∩_∩)O哈哈~ 以下为脚本（我用的是同一个表结构，但是数据要改一下，不然分不清使用结果）： 1234567891011121314151617181920-- dynamic1 ----------------------------SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for databaseinfo-- ----------------------------DROP TABLE IF EXISTS `databaseinfo`;CREATE TABLE `databaseinfo` () ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of databaseinfo-- ----------------------------INSERT INTO `databaseinfo` VALUES (&apos;1&apos;, &apos;NO.1&apos;);SET FOREIGN_KEY_CHECKS = 1;-- dynamic2 ----------------------------INSERT INTO `databaseinfo` VALUES (&apos;1&apos;, &apos;NO.2&apos;); 简易目录结构为了不浪费时间，我直接简化目录结构了 123456789101112131415161718192021222324252627java:com.maiyikai.dynamic|--- config|--- |--- DataSourceOne.java|--- |--- DataSourceTwo.java|--- controller|--- |--- DynamicDataSourceTestController.java|--- service|--- |--- DynamicDataSourceOneService.java|--- |--- DynamicDataSourceTwoService.java|--- |--- impl|--- |--- |--- DynamicDataSourceOneServiceImpl.java|--- |--- |--- DynamicDataSourceTwoServiceImpl.java|--- mapper|--- |--- DynamicTestOne.java|--- mappers|--- |--- DynamicTestTwo.java|--- entity|--- |--- DatabaseInfo.java|--- DynamicApplication.javaresources|--- mapper|--- |--- dynamicOne.xml|--- mappers|--- |--- dynamicTwo.xml|--- application.yml 需要引入的包 pom.xml引入的包就是正常连接数据库需要的包，为了使对象更高的输出在控制台，我引入了fastjson 这里使用的Spring Boot2以上版本，在配置的地方会有一些不一样 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.maiyikai&lt;/groupId&gt; &lt;artifactId&gt;dynamic&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;dynamic&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web-services&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;6.0.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.54&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml配置因为连接mysql的包的版本比较高，所以有一些多余的配置要加载数据库连接的URL上 因为使用了Spring Boot2以上版本，所以对url和driver-class更改为： jdbc-url和driver-class-name；否则获取不到对应的连接和驱动名称 因未使用了Druid，所以有一个特性是可以根据jdbc-url自动配置相关的驱动类，所以配置地方我删掉了 1234567891011121314151617181920212223242526272829server: port: 8082# druid：根据jdbc-url自动配置驱动# 不使用serverTimezone=UTC：java.sql.SQLException: The server time zone value &apos;�й���׼ʱ��&apos; is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property) to use a more specifc time zone value if you want to utilize time zone support.# 不使用useSSL=true：Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.spring: datasource: druid: test1: jdbc-url: jdbc:mysql://localhost:3306/dynamic1?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC&amp;useSSL=true username: root password: ******** validationQuery: SELECT 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 28800 testOnBorrow: false testWhileIdle: true testOnReturn: false test2: jdbc-url: jdbc:mysql://localhost:3306/dynamic2?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC&amp;useSSL=true username: root password: ******** validationQuery: SELECT 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 28800 testOnBorrow: false testWhileIdle: true testOnReturn: false 数据源配置分别配置两个不同的数据源，并设置其中一个为主数据源，否则会报错 需要对DataSource、SqlSessionFactory、SqlSessionTemplate进行配置，所以 第一个数据源（DataSourceOne.java） 1234567891011121314151617181920212223242526272829/** * 必须要有一个主数据源 */@Configuration@AutoConfigureBefore(DataSourceAutoConfiguration.class)@MapperScan(value = &quot;com.maiyikai.dynamic.mapper&quot;, sqlSessionTemplateRef = &quot;sqlSessionTemplate1&quot;)public class DataSourceOne &#123; @Bean(&quot;dynamic1DataSource&quot;) @Primary @ConfigurationProperties(prefix = &quot;spring.datasource.druid.test1&quot;) public DataSource dynamic1DataSource()&#123; return DataSourceBuilder.create().build(); &#125; @Bean(&quot;sqlSession1Factory&quot;) @Primary public SqlSessionFactory sqlSession1Factory(@Qualifier(&quot;dynamic1DataSource&quot;) DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mapper/*.xml&quot;)); return sqlSessionFactoryBean.getObject(); &#125; @Bean(&quot;sqlSessionTemplate1&quot;) @Primary public SqlSessionTemplate sqlSessionTemplate1(@Qualifier(&quot;sqlSession1Factory&quot;)SqlSessionFactory sqlSessionFactory)&#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; 第二个数据源（DataSourceTwo.java） 123456789101112131415161718192021222324252627/** * 不能与主数据源指定同一个mapper，否则不生效 */@Configuration@AutoConfigureBefore(DataSourceAutoConfiguration.class)@MapperScan(value = &quot;com.maiyikai.dynamic.mappers&quot;, sqlSessionTemplateRef = &quot;sqlSessionTemplate2&quot;)public class DataSourceTwo &#123; @Bean(&quot;dynamic1DataSource2&quot;) @ConfigurationProperties(prefix = &quot;spring.datasource.druid.test2&quot;) public DataSource dataSource()&#123; return DataSourceBuilder.create().build(); &#125; @Bean(&quot;sqlSessionFactory2&quot;) public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;dynamic1DataSource2&quot;)DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mappers/*.xml&quot;)); return sqlSessionFactoryBean.getObject(); &#125; @Bean(&quot;sqlSessionTemplate2&quot;) public SqlSessionTemplate sqlSessionTemplate(@Qualifier(&quot;sqlSessionFactory2&quot;) SqlSessionFactory sqlSessionFactory)&#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 服务类方法声明为一样的，方便（懒）…O(∩_∩)O哈哈~ 接口只拿一个做演示(DynamicDataSourceOneService.java) 123public interface DynamicDataSourceOneService &#123; DatabaseInfo getDatabaseInfo(String id);&#125; 实现类 DynamicDataSourceOneServiceImpl.java 1234567891011@Servicepublic class DynamicDataSourceOneServiceImpl implements DynamicDataSourceOneService &#123; @Autowired private DynamicTestOne dynamicTestOne; @Override public DatabaseInfo getDatabaseInfo(String id) &#123; return dynamicTestOne.getDatabaseInfoOne(id); &#125;&#125; DynamicDataSourceTwoServiceImpl.java 1234567891011@Servicepublic class DynamicDataSourceTwoServiceImpl implements DynamicDataSourceTwoService &#123; @Autowired private DynamicTestTwo dynamicTestTwo; @Override public DatabaseInfo getDatabaseInfo(String id) &#123; return dynamicTestTwo.getDatabaseInfoTwo(id); &#125;&#125; mapper及xml因为本人比较勤（hen）奋(lan),所以这里只提供一个 mapper（DynamicTestOne.java） 1234public interface DynamicTestOne &#123; DatabaseInfo getDatabaseInfoOne(@Param(&quot;id&quot;)String id);&#125; xml（dynamicOne.xml） 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.maiyikai.dynamic.mapper.DynamicTestOne&quot;&gt; &lt;select id=&quot;getDatabaseInfoOne&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;com.maiyikai.dynamic.entity.DatabaseInfo&quot;&gt; select * from databaseinfo where id=#&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 定义测试接口准备好了，就要定义接口进行测试了，当然我肯定是选择最简单，最容易访问的方式写访问啦（除了这种方法还可以使用单元测试的方式） 1234567891011121314151617181920@Controller@RequestMapping(value = &quot;/DynamicDataSource&quot;)@ResponseBodypublic class DynamicDataSourceTestController &#123; @Autowired private DynamicDataSourceOneService dynamicDataSourceOneService; @Autowired private DynamicDataSourceTwoService dynamicDataSourceTwoService; @GetMapping(&quot;/getDatabaseInfo/&#123;id&#125;&quot;) public String getDatabaseInfo(@PathVariable(&quot;id&quot;)String id)&#123; DatabaseInfo databaseInfo1 = dynamicDataSourceOneService.getDatabaseInfo(id); DatabaseInfo databaseInfo2 = dynamicDataSourceTwoService.getDatabaseInfo(id); System.err.println(&quot;databaseInfo1:===&quot;+JSON.toJSONString(databaseInfo1)); System.err.println(&quot;databaseInfo2:===&quot;+JSON.toJSONString(databaseInfo2)); return &quot;true&quot;; &#125;&#125; 启动类中没有做任何的更改，所以就不展示了 访问接口为：http://localhost:8082/DynamicDataSource/getDatabaseInfo/1（因为数据库准备的时候只准备id为1的数据，所以…）浏览器正常返回： true控制台返回：12databaseInfo1:===&#123;&quot;id&quot;:&quot;1&quot;,&quot;info&quot;:&quot;NO.1&quot;&#125;databaseInfo2:===&#123;&quot;id&quot;:&quot;1&quot;,&quot;info&quot;:&quot;NO.2&quot;&#125; 由显示结果可以看出，我们多数据源已经可以正常使用啦","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/categories/SpringBoot/"}],"tags":[{"name":"DataSource","slug":"DataSource","permalink":"https://maiyikai.github.io/tags/DataSource/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/tags/SpringBoot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://maiyikai.github.io/tags/Mybatis/"}]},{"title":"Spring Boot分表之Shardbatis插件","slug":"1554363529","date":"2019-04-04T15:40:00.000Z","updated":"2019-10-12T12:21:09.264Z","comments":true,"path":"2019/04/04/1554363529/","link":"","permalink":"https://maiyikai.github.io/2019/04/04/1554363529/","excerpt":"随着业务的发展，数据库占用的资源会越来越大；业务对数据库的增删改查操作对数据库来说都是一笔大的开销；另外，由于无法进行分布式式部署，而一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。分库分表有两种方式：垂直切分和水平切分","text":"随着业务的发展，数据库占用的资源会越来越大；业务对数据库的增删改查操作对数据库来说都是一笔大的开销；另外，由于无法进行分布式式部署，而一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。分库分表有两种方式：垂直切分和水平切分 垂直切分：即将表按照功能模块、关系密切程度划分出来，部署到不同的库上 水平切分：当一个表中的数据量过大时，我们可以把该表的数据按照某种规则进行划分，然后存储到多个结构相同的表，和不同的库上。 ————————–本文讲述分表—————————– 用代码实现分库:使用技术：Spring Boot、Mybatis、Shardbatis使用工具：Idea、MySQL建立在一个Spring Boot项目———-&gt; 创建数据库和表以下为创建的数据库和表,以及添加数据的脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for shard_1-- ----------------------------DROP TABLE IF EXISTS `shard_1`;CREATE TABLE `shard_1` ( `id` varchar(11) NOT NULL, `name` varchar(20) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- ------------------------------ Records of shard_1-- ----------------------------INSERT INTO `shard_1` VALUES (&apos;1-1&apos;, &apos;shard_1&apos;);-- ------------------------------ Table structure for shard_2-- ----------------------------DROP TABLE IF EXISTS `shard_2`;CREATE TABLE `shard_2` ( `id` varchar(11) NOT NULL, `name` varchar(20) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- ------------------------------ Records of shard_2-- ----------------------------INSERT INTO `shard_2` VALUES (&apos;2-1&apos;, &apos;shard_2&apos;);-- ------------------------------ Table structure for tables-- ----------------------------DROP TABLE IF EXISTS `tables`;CREATE TABLE `tables` ( `id` varchar(11) NOT NULL, `tableName` varchar(100) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- ------------------------------ Records of tables-- ----------------------------INSERT INTO `tables` VALUES (&apos;1-1&apos;, &apos;shard_1&apos;);INSERT INTO `tables` VALUES (&apos;2-1&apos;, &apos;shard_2&apos;); 引入依赖项目的开始，依赖是不可少的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.maiyikai&lt;/groupId&gt; &lt;artifactId&gt;shardbatis&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;shardbatis&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web-services&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--在idea中不能使用devtools包，因为会导致shardbatis里使用ApplicationContext上下文获取null--&gt; &lt;!--&lt;dependency&gt;--&gt; &lt;!--&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;--&gt; &lt;!--&lt;optional&gt;true&lt;/optional&gt;--&gt; &lt;!--&lt;/dependency&gt;--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;6.0.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.shardbatis&lt;/groupId&gt; &lt;artifactId&gt;shardbatis&lt;/artifactId&gt; &lt;version&gt;2.0.0C&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 建立目录结构目录结构随意 12345678910111213141516171819202122232425262728293031323334353637Shardbatis|--- pom.xml|--- src| |--- main| | |--- java| | | |--- controller| | | | |--- com| | | | | |--- maiyikai| | | | | | |--- shardbatis| | | | | | | |--- controller| | | | | | | | |--- ShardbatisController.java| | | | | | | |--- service| | | | | | | | |--- ShardService.java| | | | | | | | |------ TablesService.java| | | | | | | | |--- impl| | | | | | | | | |--- ShardServiceImpl.java| | | | | | | | | |--- TablesServiceImpl.java| | | | | | | |--- mapper| | | | | | | | |--- ShardMapper.java| | | | | | | | |--- TablesMapper.java| | | | | | | |--- config| | | | | | | | |--- ShardConfiguration.java| | | | | | | |---- entity| | | | | | | | |------ Shard.java| | | | | | | | |--- Tables.java| | | | | | | |-- strategy| | | | | | | | |--- MyShardStrategy.java| | | | | | | |--- tools| | | | | | | | |--- SpringContextAware.java | | | | | | | |--- ShardbatisApplication.java | | |--- resources| | | |--- mapper| | | | |--- shard.xml| | | | |--- tables.xml| | | |--- shard| | | | |--- shard_config.xml| | | |--- application.yml 编写配置文件12345678910111213141516171819202122232425server: port: 8181spring: datasource: druid: url: jdbc:mysql://localhost:3306/shardbatis?useUnicode=true&amp;characterEncoding=UTF8&amp;&amp;serverTimezone=UTC&amp;useSSL=false username: root password: maiyikai min-idle: 5 max-active: 150 max-wait: 60000 pool-prepared-statements: false max-open-prepared-statements: 0 validation-query: select &apos;x&apos; test-while-idle: true test-on-borrow: true test-on-return: false time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 mybatis: mapper-locations: classpath:mapper/*.xmllogging: level: com.maiyikai.shardbatis.mapper: debug # 调试打印sql 开始写代码了直接就是代码 ShardbatisController.java启动代码没什么不需要更改其他的东西 123456789@SpringBootApplication@MapperScan(value = &quot;com.maiyikai.shardbatis.mapper&quot;)//扫描mapper类public class ShardbatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardbatisApplication.class, args); &#125;&#125; 配置ShardConfiguration.java通过 ShardPlugin.java 源码，ShardPlugin 通过读取属性值 shardingConfig 获取配置文件，所以这个值不能改 12345678910111213@Configurationpublic class ShardConfiguration &#123; @Bean(name = &quot;shardPlugin&quot;) public ShardPlugin shardPlugin()&#123; ShardPlugin shardPlugin = new ShardPlugin(); Properties properties = new Properties(); properties.put(&quot;shardingConfig&quot;, &quot;shard/shard_config.xml&quot;);//文件加载--键值必须为shardingConfig，这是类的内部要求，否则加载失败 shardPlugin.setProperties(properties); return shardPlugin; &#125;&#125; ShardbatisController.java定义接口，使用GetMapping是为了方便使用浏览器访问 1234567891011121314@Controller@RequestMapping(value = &quot;/Shardbatis&quot;)public class ShardbatisController &#123; @Autowired private ShardService shardService; @ResponseBody @GetMapping (value = &quot;/startShard&quot;) public String test(@RequestParam(value = &quot;id&quot;) String id)&#123; return shardService.getName(id); &#125;&#125; ShardServiceImpl.java略过服务类中的代码 123456789101112@Servicepublic class ShardServiceImpl implements ShardService &#123; @Autowired private ShardMapper shardMapper; @Override public String getName(String id) &#123; Shard shard = shardMapper.getShardResult(id);//执行到这条语句时，会被拦截进入到分表策略MyShardStrategy.java中，获取对应的表名称，并且更改sql中的表名 return StringUtils.isEmpty(shard.getName())?null:shard.getName(); &#125;&#125; TablesService.java用于获取对应的表名 1234567891011121314151617@Service(&quot;tablesService&quot;)public class TableServiceImpl implements TablesService &#123; @Autowired private TablesMapper tablesMapper; /** * 因为分表的表名对应的信息存放在tables表中，所以通过这个方法访问，通过对饮的id获取对饮的表名 * @param id * @return */ @Override public String getTableName(String id) &#123; Tables tables = tablesMapper.getTables(id); return StringUtils.isEmpty(tables.getTableName())?null:tables.getTableName(); &#125;&#125; SpringContextAware.java用于普通类可获取ApplicationContext使用，可以通过该applicationContext获取对应的Spring Boot应用中的Bean 1234567891011121314151617@Componentpublic class SpringContextAware implements ApplicationContextAware &#123; private static ApplicationContext applicationContexts;//使用静态，让它存储下来,通过类型即可获取 @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; applicationContexts = applicationContext; &#125; public static ApplicationContext getApplicationContexts() &#123; return applicationContexts; &#125; public static &lt;T&gt; T getBean(String name)&#123; return (T) getApplicationContexts().getBean(name); &#125;&#125; MyShardStrategy.java策略类 123456789101112/** * 继承ShardStrategy类 */public class MyShardStrategy implements ShardStrategy &#123; @Override public String getTargetTableName(String baseTableName, Object params, String mapperId) &#123; String id = ((Map&lt;String, String&gt;)params).get(&quot;id&quot;);//解析参数，获取需要的参数 TablesService tablesService = SpringContextAware.getBean(&quot;tablesService&quot;);//获取对应的Bean return tablesService.getTableName(id); &#125;&#125; shard.xml省略mapper类表名一定要和shard_config.xml中配置的表名一致，否则将报错 12345&lt;mapper namespace=&quot;com.maiyikai.shardbatis.mapper.ShardMapper&quot;&gt; &lt;select id=&quot;getShardResult&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;com.maiyikai.shardbatis.entity.Shard&quot;&gt; SELECT name FROM shard WHERE id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; tables.xml省略mapper类 12345&lt;mapper namespace=&quot;com.maiyikai.shardbatis.mapper.TablesMapper&quot;&gt; &lt;select id=&quot;getTables&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;com.maiyikai.shardbatis.entity.Tables&quot;&gt; SELECT * FROM tables WHERE id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; shard_config.xml分表策略配置文件ignoreList：忽略集合parseList：解释集合–需要操作的集合strategy：指定tableName对应的strategy 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE shardingConfig PUBLIC &quot;-//shardbatis.googlecode.com//DTD Shardbatis 2.0//EN&quot; &quot;http://shardbatis.googlecode.com/dtd/shardbatis-config.dtd&quot;&gt;&lt;shardingConfig&gt; &lt;!-- 忽略不进行分表策略的mapperid-即对应的方法 --&gt; &lt;ignoreList&gt; &lt;value&gt;&lt;/value&gt; &lt;/ignoreList&gt; &lt;!-- 进行分表策略的mapperid-即对应的方法;一定要精确到方法，否则不会被拦截 --&gt; &lt;parseList&gt; &lt;value&gt;com.maiyikai.shardbatis.mapper.ShardMapper.getShardResult&lt;/value&gt; &lt;/parseList&gt; &lt;!-- 指定表使用对应的策略 --&gt; &lt;strategy tableName=&quot;shard&quot; strategyClass=&quot;com.maiyikai.shardbatis.strategy.MyShardStrategy&quot;/&gt;&lt;/shardingConfig&gt; 至此，代码编写完成，执行接口即可进行分表，分表的策略根据业务进行调整 访问路劲:http://localhost:8181/Shardbatis/startShard?id=2-1当id为2-1时 : 返回结果为:shard_2（代表访问的表）当id为1-1时 : 返回结果为shard_1（代表访问的表）","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/tags/SpringBoot/"},{"name":"Shardbatis","slug":"Shardbatis","permalink":"https://maiyikai.github.io/tags/Shardbatis/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://maiyikai.github.io/tags/Mybatis/"}]},{"title":"Spring Boot启动原理","slug":"1553480412","date":"2019-03-22T10:20:00.000Z","updated":"2019-10-12T12:21:09.264Z","comments":true,"path":"2019/03/22/1553480412/","link":"","permalink":"https://maiyikai.github.io/2019/03/22/1553480412/","excerpt":"SpringBoot启动原理参考1：Spring Boot的启动过程三：SpringApplication.run()参考2：面试官问我，SpringApplication.run做了哪些事？","text":"SpringBoot启动原理参考1：Spring Boot的启动过程三：SpringApplication.run()参考2：面试官问我，SpringApplication.run做了哪些事？ 如何启动一个SpringBoot应用？123456public class Test&#123; public static void main(String[] args)&#123; SpringApplication springApplication = new SpringApplication(Test.class); springApplication.run(args); &#125;&#125; 解析创建SpringApplication对象源码1SpringApplication构造方法： 123public SpringApplication(Object... sources) &#123; initialize(sources);&#125; 源码2（initialize(…)）初始化SpringAppcation 123456789101112131415private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前应用是否为WEB应用 this.webEnvironment = deduceWebEnvironment(); //通过类路径META-INF/spring.factories文件获取ApplicationContextInitializer类型的实例，并保存 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //通过类路径META-INF/spring.factories文件获取ApplicationListener类型的实例，并保存 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 源码3 getSpringFactoriesInstances（…）获取通过META-INF/spring.factories文件获取到的对应的类路径下的实例 123456789101112131415161718//通过类路径META-INF/spring.factories文件获取ApplicationContextInitializer类型的实例private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;);&#125; private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates //通过类路径META-INF/spring.factories文件获取ApplicationContextInitializer.class类型的类名 Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); //获取实例 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 源码4(deduceMainApplicationClass())从运行类的堆栈中获取含有main方法的类 123456789101112131415//从运行类的堆栈中获取含有main方法的类private Class&lt;?&gt; deduceMainApplicationClass() &#123; try &#123; StackTraceElement[] stackTrace = new RuntimeException().getStackTrace(); for (StackTraceElement stackTraceElement : stackTrace) &#123; if (&quot;main&quot;.equals(stackTraceElement.getMethodName())) &#123; return Class.forName(stackTraceElement.getClassName()); &#125; &#125; &#125; catch (ClassNotFoundException ex) &#123; // Swallow and continue &#125; return null;&#125; 解析springApplication.run(args)源码1(run(…))run方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public ConfigurableApplicationContext run(String... args) &#123; //跑马灯对象--用于记录运行时间 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //通过META-INF/spring.factories获取SpringApplicationRunListener类型的实例 SpringApplicationRunListeners listeners = getRunListeners(args); //遍历回调SpringApplicationRunListener的starting方法--既启动监听器 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //环境准备，完成后遍历回调SpringApplicationRunListener的environmentPrepared方法对监听器配置环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //打印Banner-既控制台显示的Spring.... Banner printedBanner = printBanner(environment); //根据创建的环境判断，是创建web容器，还是普通的IOC容器 context = createApplicationContext(); //注册异常分析器 analyzers = new FailureAnalyzers(context); //准备上下文 //遍历回调ApplicationContextInitializer的initialize事件 //遍历回调SpringApplicationRunListeners中的contextPrepared事件 //环境准备完成之后，遍历回调SpringApplicationRunListeners中的contextLoaded事件 prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新上下文，初始化所有自动配置类 refreshContext(context); //遍历所有注册的ApplicationRunner和CommandLineRunner，并执行其run()方法 afterRefresh(context, applicationArguments); //调用所有的SpringApplicationRunListener的finished()方法，广播SpringBoot已经完成了ApplicationContext初始化的全部过程 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 源码2(getRunListeners(…))通过类路径META-INF/spring.factories文件获取ApplicationContextInitializer类型的实例，并将其封装到SpringApplicationRunListeners实例 1234567//创建实例 SpringApplicationRunListenersprivate SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; //通过META-INF/spring.factories获取SpringApplicationRunListener类型的实例 return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances( SpringApplicationRunListener.class, types, this, args));&#125; 源码3(prepareEnvironment(…))准备环境 1234567891011121314151617//准备环境private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment //创建环境 ConfigurableEnvironment environment = getOrCreateEnvironment(); //配置环境 configureEnvironment(environment, applicationArguments.getSourceArgs()); //遍历回调SpringApplicationRunListener的environmentPrepared方法 listeners.environmentPrepared(environment); if (!this.webEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()) .convertToStandardEnvironmentIfNecessary(environment); &#125; return environment;&#125; 源码4(createApplicationContext())根据创建的环境判断，是创建web容器，还是普通的IOC容器 1234567891011121314151617//根据创建的环境判断，是创建web容器，还是普通的IOC容器protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; contextClass = Class.forName(this.webEnvironment ? DEFAULT_WEB_CONTEXT_CLASS : DEFAULT_CONTEXT_CLASS); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( &quot;Unable create a default ApplicationContext, &quot; + &quot;please specify an ApplicationContextClass&quot;, ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiate(contextClass);&#125; 源码5(prepareContext(…))准备上下文 123456789101112131415161718192021222324252627282930//准备上下文private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; //设置环境 context.setEnvironment(environment); postProcessApplicationContext(context); //遍历回调ApplicationContextInitializer的initialize事件--即上下文注入并初始化 applyInitializers(context); //遍历回调SpringApplicationRunListeners中的contextPrepared事件--即上下注入 listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans context.getBeanFactory().registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; // Load the sources Set&lt;Object&gt; sources = getSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); load(context, sources.toArray(new Object[sources.size()])); //遍历回调SpringApplicationRunListeners中的contextLoaded事件--即加载上下文 listeners.contextLoaded(context);&#125; 综上，SpringApplication.run()总共做了两件是： 创建了SpringApplication对象，初始化的时候，判断是否为WEB应用，并将通过配置文件META-INF/spring.factories找到对应的上下文类路径和监听器路径，将其实例化并且保存起来。 运行run方法，通过配置文件META-INF/spring.factories找到对应的监听器路径，将其实例化并启动。创建环境和创建上下文，并为监听器配置。刷新上下文，然后调用所有的监听器的finished()方法，广播SpringBoot已经完成了。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/tags/SpringBoot/"}]},{"title":"怒怼HashMap","slug":"1552012657","date":"2019-03-08T10:00:00.000Z","updated":"2019-10-12T12:21:09.263Z","comments":true,"path":"2019/03/08/1552012657/","link":"","permalink":"https://maiyikai.github.io/2019/03/08/1552012657/","excerpt":"本文呈现HashMap工作原理，和关于HashTable、ConcurrentHashMap的区别一起来揭晓吧… …","text":"本文呈现HashMap工作原理，和关于HashTable、ConcurrentHashMap的区别一起来揭晓吧… … 什么是HashMap? HashMap采用了“数组+链表+红黑树”的数据结构，能在查询和修改的时候继承了数组的线性查找和链表的寻址修改。 存储方式是以键值对的方式进行存储(即:key-value)，HashMap可以存储为Null的键于值，而HashTable不支持（通过查看源码可知，HashTable获取的键值对分别是两个对象，判断对象为Null就抛异常；而HashMap则是通过处理，所以支持） HashMap是非线程安全的，HashTable是线程安全的，所以HashMap效率比较快 HashMap的工作原理？ HashMap基于hashing的原理，我们使用put(key, value)存储对象到HashMap，使用get(key)从HashMap对象中获取对象。当我们调用put()方法时，会先对key调用hashCode()，计算并返回hashCode用于在Map中找到对应的bucket位置存储Node对象。 HashMap的初始长度为16 HashMap负载因子为0.75 当HashMap的容量达到16*0.75=12时，就需要HashMap扩容，即扩容为原来的2倍,来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 如果链表长度超过阀值( TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于6，就把红黑树转回链表 如果两个对象的hashCode一致，会有什么后果？因为HashMap的存储器的对象是通过key的hashCode来确认应该存放在哪一个bucket的位置，由于hashCode一致，所以会找到同一个bucket的位置，并将对象以链表的形势存放在这个bucket位置下 如果发生了碰撞，应该如何通过key取到值对象？当我们调用get(key)方法时，会通过key计算其hahshCode，找到对应的bucket位置，再通过调用key.equals()方法在链表中找到正确的节点，最终找到值对象。 减少碰撞的方法？ 扰动函数可以减少碰撞，原理是如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这就意味着存链表结构减小，这样取值的话就不会频繁调用equal方法，这样就能提高HashMap的性能。（扰动即Hash方法内部的算法实现，目的是让不同对象返回不同hashcode。） 使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。为什么String, Interger这样的wrapper类适合作为键？因为String是final的，而且已经重写了equals()和hashCode()方法了。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。 HashMap中hash函数怎么实现？ key hash null 0 not null h = key.hashCode(); hash = h ^ (h &gt;&gt;&gt; 16); 因为HashMap支持键为null，所以有两组算法 如何计算HashMap的下标？ 假设HashMap的数组长度为len 假设键的hashCode为 hash = key.hashCode() 下标: (len - 1) &amp; (hash ^ (hash &gt;&gt;&gt; 16)) 重新调整HashMap大小存在什么问题吗？当多线程的情况下，可能产生条件竞争。当重新调整HashMap大小的时候，确实存在条件竞争，如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的数组位置的时候，HashMap并不会将元素放在LinkedList的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了 为什么选用红黑树，而不选用二叉查找树？之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持“平衡”是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于8的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。 红黑树的特性（摘抄维基百科） 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 HashMap和HashTable的区别？ hash值得计算不一样 HashMap： (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) HashTable: h = key.hashCode() 下标计算不一样 HashMap: (tableLength -1) &amp; (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) HashTable: ((h = key.hashCode()) &amp; 0x7FFFFFFF) % tableLength HashMap是非线程安全，HashTable是线程安全的。 单线程使用情况下，HashMap的效率会更快 负载因子是相同的：0.75 默认大小和扩容方案不一样： HashMap: 默认大小为16， 扩容：tableLength * 2 HashTable: 默认大小为11， 扩容： tableLength * 2 + 1 HashTable对每个方法都添加了synchronized关键字 ConcurrentHashMap hash计算: h = key.hashCode(); (h ^ (h &gt;&gt;&gt; 16) &amp; 0x7fffffff) 下标计算: i = (tableLength - 1) &amp; hash 初始值16 负载因子：0.75 当ConcurrentHashMap的容量达到16*0.75=12时，就需要ConcurrentHashMap扩容 ConcurrentHashMap采用了分段锁技术，线程安全","categories":[{"name":"Java","slug":"Java","permalink":"https://maiyikai.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://maiyikai.github.io/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"https://maiyikai.github.io/tags/HashMap/"}]},{"title":"技术区别汇总整理","slug":"1548754788","date":"2019-02-19T10:00:00.000Z","updated":"2019-10-12T12:21:09.263Z","comments":true,"path":"2019/02/19/1548754788/","link":"","permalink":"https://maiyikai.github.io/2019/02/19/1548754788/","excerpt":"为了新工作面试，进行技术对比整理包含内容： Spring、Spring Boot、Mybatis、Ibatis、Hibernate、Mysql、Oracle、Redis、MongoDB、FastJson、Gson（后续会增加）","text":"为了新工作面试，进行技术对比整理包含内容： Spring、Spring Boot、Mybatis、Ibatis、Hibernate、Mysql、Oracle、Redis、MongoDB、FastJson、Gson（后续会增加） Spring Boot和Spring的区别 Spring Boot是Spring开源组织下的子项目，是Spring组件一站式解决方案，主要简化了Spring的难度，简省了繁重的配置，提供了各种start(启动器)。 SpringBoot内置了内置了Tomcat/Jetty等容器，而且内嵌了各种servlet容器，Spring Boot只要打成一个可执行的jar包就能独立运行，而Spring只能包为war包，然后将其放置在可执行的服务器容器中执行。 Spring Boot提供一系列端点可以监控服务及应用，做健康检测。 Spring 最初利用“工厂模式”（ DI ）和“代理模式”（ AOP ）解耦应用组件。大家觉得挺好用，于是按照这种模式搞了一个 MVC 框架（一些用 Spring 解耦的组件），用开发 web 应用（ SpringMVC ）。然后有发现每次开发都要搞很多依赖，写很多样板代码很麻烦，于是搞了一些懒人整合包（ starter ），这套就是 Spring Boot 。 Mybatis和Ibatis区别 相同点： 都是dao层框架 都有SqlMapConfig.xml文件和dao层编写sql语句的xml文件 都需要配置数据源 都使用了jdbc事务 都可以为实体类起别名 映射文件中都可以写sql语句，都有namespace命名空间 不同点： Ibatis中 在标签中编写sql语句，并且可以给实体类起别名 接受参数方式是使用#参数#或者$参数$ 参数类型是用parameterClass，返回值类型是用resultClass Mybatis中 在中编写sql语句，并且不能在mapper中给实体类起别名 接收参数的方式是使用#{参数}或者${参数}（ONGL表达式） 参数类型用的是parameterType，返回值类型用的是resultType 支持使用注解方式直接在Mapper接口上编写sql dao层中 ibatis中如果定义接口需要实现接口，并且在实现类中需要读取配置文件，得到sqlMapClient对象才能使用对应的方法 Mybaits中只需要定义接口，然后在命名空间中连接上接口路径就可以使用 Mybatis和Hibernate的区别（网摘）第一方面：开发速度的对比就开发速度而言，Hibernate的真正掌握要比Mybatis来得难些。Mybatis框架相对简单很容易上手，但也相对简陋些。个人觉得要用好Mybatis还是首先要先理解好Hibernate。 比起两者的开发速度，不仅仅要考虑到两者的特性及性能，更要根据项目需求去考虑究竟哪一个更适合项目开发，比如：一个项目中用到的复杂查询基本没有，就是简单的增删改查，这样选择hibernate效率就很快了，因为基本的sql语句已经被封装好了，根本不需要你去写sql语句，这就节省了大量的时间，但是对于一个大型项目，复杂语句较多，这样再去选择hibernate就不是一个太好的选择，选择mybatis就会加快许多，而且语句的管理也比较方便。 数据库切换：当从MySQL迁移到Oracle时，SQL也会相应的进行更改。因为Mybatis的SQL是开发人员自己编写的，所以在迁移数据库时，要对SQL进行对应的更改。而Hibernate在配置的时候指定了数据库，如果要切换数据库时，只需更改配置即可，也就是说Hibernate支持多种数据的语言，不需要对其进行大的更改。 第二方面：开发工作量的对比Hibernate和MyBatis都有相应的代码生成工具。可以生成简单基本的DAO层方法。针对高级查询，Mybatis需要手动编写SQL语句，以及ResultMap。而Hibernate有良好的映射机制，开发者无需关心SQL的生成与结果映射，可以更专注于业务流程。 第三方面：sql优化方面Hibernate的查询会将表中的所有字段查询出来，这一点会有性能消耗。Hibernate也可以自己写SQL来指定需要查询的字段，但这样就破坏了Hibernate开发的简洁性。而Mybatis的SQL是手动编写的，所以可以按需求指定查询的字段。 Hibernate HQL语句的调优需要将SQL打印出来，而Hibernate的SQL被很多人嫌弃因为太丑了。MyBatis的SQL是自己手动写的所以调整方便。但Hibernate具有自己的日志统计。Mybatis本身不带日志统计，使用Log4j进行日志记录。 第四方面：对象管理的对比Hibernate 是完整的对象/关系映射解决方案，它提供了对象状态管理（state management）的功能，使开发者不再需要理会底层数据库系统的细节。也就是说，相对于常见的 JDBC/SQL 持久层方案中需要管理 SQL 语句，Hibernate采用了更自然的面向对象的视角来持久化 Java 应用中的数据。 换句话说，使用 Hibernate 的开发者应该总是关注对象的状态（state），不必考虑 SQL 语句的执行。这部分细节已经由 Hibernate 掌管妥当，只有开发者在进行系统性能调优的时候才需要进行了解。而MyBatis在这一块没有文档说明，用户需要对对象自己进行详细的管理。 第五方面：缓存机制 Hibernate缓存 Hibernate一级缓存是Session缓存，利用好一级缓存就需要对Session的生命周期进行管理好。建议在一个Action操作中使用一个Session。一级缓存需要对Session进行严格管理。 Hibernate二级缓存是SessionFactory级的缓存。 SessionFactory的缓存分为内置缓存和外置缓存。内置缓存中存放的是SessionFactory对象的一些集合属性包含的数据(映射元素据及预定SQL语句等),对于应用程序来说,它是只读的。外置缓存中存放的是数据库数据的副本,其作用和一级缓存类似.二级缓存除了以内存作为存储介质外,还可以选用硬盘等外部存储设备。二级缓存称为进程级缓存或SessionFactory级缓存，它可以被所有session共享，它的生命周期伴随着SessionFactory的生命周期存在和消亡。 MyBatis缓存 MyBatis 包含一个非常强大的查询缓存特性,它可以非常方便地配置和定制。MyBatis 3 中的缓存实现的很多改进都已经实现了,使得它更加强大而且易于配置。 默认情况下是没有开启缓存的,除了局部的 session 缓存,可以增强变现而且处理循环 依赖也是必须的。要开启二级缓存,你需要在你的 SQL 映射文件中添加一行: 字面上看就是这样。这个简单语句的效果如下: 映射语句文件中的所有 select 语句将会被缓存。 映射语句文件中的所有 insert,update 和 delete 语句会刷新缓存。 缓存会使用 Least Recently Used(LRU,最近最少使用的)算法来收回。 根据时间表(比如 no Flush Interval,没有刷新间隔), 缓存不会以任何时间顺序 来刷新。 缓存会存储列表集合或对象(无论查询方法返回什么)的 1024 个引用。 缓存会被视为是 read/write(可读/可写)的缓存,意味着对象检索不是共享的,而 且可以安全地被调用者修改,而不干扰其他调用者或线程所做的潜在修改。 所有的这些属性都可以通过缓存元素的属性来修改。 比如: 这个更高级的配置创建了一个 FIFO 缓存,并每隔 60 秒刷新,存数结果对象或列表的 512 个引用,而且返回的对象被认为是只读的,因此在不同线程中的调用者之间修改它们会导致冲突。可用的收回策略有, 默认的是 LRU: LRU – 最近最少使用的:移除最长时间不被使用的对象。 FIFO – 先进先出:按对象进入缓存的顺序来移除它们。 SOFT – 软引用:移除基于垃圾回收器状态和软引用规则的对象。 WEAK – 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。 flushInterval(刷新间隔)可以被设置为任意的正整数,而且它们代表一个合理的毫秒 形式的时间段。默认情况是不设置,也就是没有刷新间隔,缓存仅仅调用语句时刷新。 size(引用数目)可以被设置为任意正整数,要记住你缓存的对象数目和你运行环境的 可用内存资源数目。默认值是1024。 readOnly(只读)属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓 存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。可读写的缓存 会返回缓存对象的拷贝(通过序列化) 。这会慢一些,但是安全,因此默认是 false。 相同点：Hibernate和Mybatis的二级缓存除了采用系统默认的缓存机制外，都可以通过实现你自己的缓存或为其他第三方缓存方案，创建适配器来完全覆盖缓存行为。 不同点 Hibernate的二级缓存配置在SessionFactory生成的配置文件中进行详细配置，然后再在具体的表-对象映射中配置是那种缓存。 MyBatis的二级缓存配置都是在每个具体的表-对象映射中进行详细配置，这样针对不同的表可以自定义不同的缓存机制。并且Mybatis可以在命名空间中共享相同的缓存配置和实例，通过Cache-ref来实现。 两者比较 Hibernate: Hibernate对查询对象有着良好的管理机制，用户无需关心SQL。所以在使用二级缓存时如果出现脏数据，系统会报出错误并提示。 MyBatis: MyBatis在这一方面，使用二级缓存时需要特别小心。如果不能完全确定数据更新操作的波及范围，避免Cache的盲目使用。否则，脏数据的出现会给系统的正常运行带来很大的隐患。 第六方面：总结*相同点：Hibernate与MyBatis都可以是通过SessionFactoryBuider由XML配置文件生成SessionFactory，然后由SessionFactory 生成Session，最后由Session来开启执行事务和SQL语句。其中SessionFactoryBuider，SessionFactory，Session的生命周期都是差不多的。 Hibernate和MyBatis都支持JDBC和JTA事务处理。 Mybatis优势 MyBatis可以进行更为细致的SQL优化，可以减少查询字段。 MyBatis容易掌握，而Hibernate门槛较高。 Hibernate优势 Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。 Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。 Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。 Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳。 Mysql和oracle区别 Oracle是大型数据库，MySQL是中小型数据库 Oracle是收费的，MySQL是开源的 Oracle支持大并发、大访问量，是OLTP最好的工具（On-Line Transaction Processing联机事务处理过程） Oracle所需空间比较大，MySQL比较小 使用的时候Oracle占用特别大的内存空间和其他机器性能 Oracle也Mysql操作上的区别 主键 MYSQL有自动增长的数据类型，在创建表时只要指定表的主键为auto increment,插入记录时，不需要再指定该记录的主键值，Mysql将自动增长。ORACLE没有自动增长的数据类型，需要建立一个自动增长的序列号，插入记录时要把序列号的下一个值赋于此字段。 单引号的处理 MYSQL里可以用双引号包起字符串，ORACLE里只可以用单引号包起字符串。在插入和修改字符串前必须做单引号的替换：把所有出现的一个单引号替换成两个单引号。 翻页的SQL语句的处理 MYSQL处理翻页的SQL语句比较简单，用LIMIT 开始位置, 记录个数；ORACLE处理翻页的SQL语句就比较繁琐了。每个结果集只有一个ROWNUM字段标明它的位置, 并且只能用 ROWNUM&lt;100, 不能用ROWNUM&gt;80 长字符串的处理 长字符串的处理ORACLE也有它特殊的地方。INSERT和UPDATE时最大可操作的字符串长度小于等于4000个单字节, 如果要插入更长的字符串, 请考虑字段用CLOB类型，方法借用 ORACLE里自带的DBMS_LOB程序包。插入修改记录前一定要做进行非空和长度判断，不能为空的字段值和超出长度字段值都应该提出警告,返回上次操作。 空字符的处理 MYSQL的非空字段也有空的内容，ORACLE里定义了非空字段就不容许有空的内容。按MYSQL的NOT NULL来定义ORACLE表结构, 导数据的时候会产生错误。因此导数据时要对空字符进行判断，如果为NULL或空字符，需要把它改成一个空格的字符串。 字符串的模糊比较 MYSQL里用 字段名 like ‘%字符串%’,ORACLE里也可以用 字段名 like ‘%字符串%’ 但这种方法不能使用索引, 速度不快。用字符串比较函数 instr(字段名,’字符串’)&gt;0 会得到更精确的查找结果。 日期字段的处理 MYSQL日期字段分DATE和TIME两种，ORACLE日期字段只有DATE，包含年月日时分秒信息，用当前数据库的系统时间为SYSDATE, 精确到秒，或者用字符串转换成日期型函数TO_DATE(‘&lt;st1:chsdate isrocdate=”False” islunardate=”False” day=”1” month=”8” year=”2001”&gt;2001-08-01&lt;/st1:chsdate&gt;’,’YYYY-MM-DD’)年-月-日 24小时:分钟:秒 的格式YYYY-MM-DD HH24:MI:SS TO_DATE()还有很多种日期格式, 可以参看ORACLE DOC.日期型字段转换成字符串函数TO_CHAR(‘&lt;st1:chsdate isrocdate=”False” islunardate=”False” day=”1” month=”8” year=”2001”&gt;2001-08-01&lt;/st1:chsdate&gt;’,’YYYY-MM-DD HH24:MI:SS’) 日期字段的数学运算公式有很大的不同。MYSQL找到离当前时间7天用 DATE_FIELD_NAME &gt; SUBDATE（NOW（），INTERVAL 7 DAY）ORACLE找到离当前时间7天用 DATE_FIELD_NAME &gt;SYSDATE - 7; 对于事务的支持 这一点也是大家经常说到的，MySQL对于事务默认是不支持的，只有某些存储引擎中如：innodb可以支持。而Oracle对于事务是完全支持，不管是OLTP还是OLAT都是支持的 MySQL是单进程多线程，Oracle是多进程（在Windows下也是单进程） 数据库和实例以及用户之间的关系。我们知道用户操作数据库不管MySQL还是Oracle都是通过实例来的，那么实例和数据库、数据库软件以及用户之间是什么关系呢?在MySQL和Oracle的情况下我们来分别讲解下： 首先MySQL的实例是用户登录是系统分配给用户的，而用户必须是先在MySQL中创建好，然后登陆用户mysql -u user_name -p然后使用show databases; 命令查看数据库，在使用 use database_name database; 选择数据库,这样才可以对数据库进行操作。简单的关系就是：instance &gt; database 其次是Oracle，Oracle的实例是在创建数据库时就默认创建好的，而用户基于数据库实例，实例之间可以没有关系所以其中的用户也不尽相同，你登录不同的实例就相当于登录了不同的数据库，登陆的命令也能简单sqlplus user_name/password@IP:port/instance_name 其中可以把IP地址，端口号，实例名写在一个TNS文件中取一个别名，登陆的时候输入这个别名就行了。简单的关系就是：instance = database MySQL、Redis和MongoDB的区别 数据库类型 关系型数据库 MySQL 非关系型数据库 Redis MongoDB 储存位置 MySQL 数据和索引都存放在硬盘中，只有要使用的时候才会存放到内存，所以MySQL可以存放源大于内存容量的数据 Redis Redis所有数据都存放在内存中，是一个不折不扣的内存数据库 MongoDB 内存数据库，数据都是存放在内存里面。对数据的操作大部分都在内存中，但mongodb并不是单纯的内存数据库。 事务 MySQL 部分引擎的存储方式支持事务 如：Innodb存储引擎 Redis、MongoDB 不支持事务 持久化 持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。 Redis 使用RDB方式和AOF方式 RDB持久化也分两种：SAVE和BGSAVE SAVE是阻塞式的RDB持久化，当执行这个命令时redis的主进程把内存里的数据库状态写入到RDB文件中，直到该文件创建完毕的这段时间内redis将不能处理任何命令请求。 BGSAVE属于非阻塞式的持久化，它会创建一个子进程专门去把内存中的数据库状态写入RDB文件里，同时主进程还可以处理来自客户端的命令请求。但子进程基本是复制的父进程，这等于两个相同大小的redis进程在系统上运行，会造成内存使用率的大幅增加。 AOF 与RDB的保存整个redis数据库状态不同，AOF是通过保存对redis服务端的写命令（如set、sadd、rpush）来记录数据库状态的，即保存你对redis数据库的写操作 MongoDB MongoDB的所有数据实际上是存放在硬盘的，所有要操作的数据通过mmap的方式映射到内存某个区域内。然后，MongoDB就在这块区域里面进行数据修改，避免了零碎的硬盘操作。至于mmap上的内容flush到硬盘就是操作系统的事情了，所以，如果，MongoDB在内存中修改了数据后，mmap数据flush到硬盘之前，系统宕机了，数据就会丢失。 MongoDB持久化原理：MongoDB在启动时，专门初始化一个线程不断循环（除非应用crash掉），用于在一定时间周期内来从defer队列中获取要持久化的数据并写入到磁盘的journal(日志)和mongofile(数据)处，当然因为它不是在用户添加记录时就写到磁盘上，所以按MongoDB开发者说，它不会造成性能上的损耗，因为看过代码发现，当进行CUD操作时，记录(Record类型)都被放入到defer队列中以供延时批量（groupcommit）提交写入，但相信其中时间周期参数是个要认真考量的参数，系统为90毫秒，如果该值更低的话，可能会造成频繁磁盘操作，过高又会造成系统宕机时数据丢失过。 集群 全部支持 数据量和性能的比较 当物理内存够用的时候，Redis &gt; MongoDB &gt; MySQL 当物理内存不够用的时候，Redis 和 MongoDB 都会使用虚拟内存。 实际上如果Redis要开始虚拟内存，那很明显要么加内存条，要么你就该换个数据库了。 但是，MongoDB 不一样，只要，业务上能保证，冷热数据的读写比，使得热数据在物理内存中，mmap 的交换较少。 MongoDB 还是能够保证性能。有人使用 MongoDB 存储了上T的数据。 MySQL，MySQL根本就不需要担心数据量跟内存下的关系。不过，内存的量跟热数据的关系会极大地影响性能表现。 当物理内存和虚拟内存都不够用的时候，估计除了 MySQL 你没什么好选择了。 其实，从数据存储原理来看，我更倾向于将 MongoDB 归类为硬盘数据库，但是使用了 mmap 作为加速的手段而已。 简说mmap mmap系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件进行操作。 mmap 系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用。 read()，write（）等操作。mmap并不分配空间, 只是将文件映射到调用进程的地址空间里, 然后你就可以用memcpy等操作写文件, 而不用write()了.写完后用msync()同步一下, 你所写的内容就保存到文件里了. 不过这种方式没办法增加文件的长度, 因为要映射的长度在调用mmap()的时候就决定了。 优缺点 MySQL 优点 体积小、速度快、总体拥有成本低，开源，提供的接口支持多种语言连接操作。 支持多种操作系统。 MySQL 的核心程序采用完全的多线程编程。线程是轻量级的进程，它可以灵活地为用户提供服务，而不过多的系统资源。用多线程和C语言实现的MySQL 能很容易充分利用CPU。 MySQL 有一个非常灵活而且安全的权限和口令系统。当客户与MySQL 服务器连接时，他们之间所有的口令传送被加密，而且MySQL 支持主机认证。 MySQL 能够提供很多不同的使用者界面，包括命令行客户端操作，网页浏览器，以及各式各样的程序语言界面，例如 C++，Perl，Java，PHP，以及Python。你可以使用事先包装好的客户端，或者干脆自己写一个合适的应用程序。MySQL可用于 Unix，Windows，以及OS/2等平台，因此它可以用在个人电脑或者是服务器上。 缺点 不支持热备份。 MySQL不支持自定义数据类型。 MySQL最大的缺点是其安全系统，主要是复杂而非标准，另外只有到调用mysqladmin来重读用户权限时才发生改变。 MySQL对存储过程和触发器支持不够良好。 尽管 MySQL 理论上仍是开源产品，也有人抱怨它诞生之后更新缓慢。然而，应该注意到有一些基于 MySQL 并完整集成的数据库（如 MariaDB），在标准的 MySQL 基础上带来了额外价值。 MySQL对XML支持不够良好。 Redis 优点 读写性能优异。 支持数据持久化，支持 AOF 和 RDB 两种持久化方式。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 数据结构丰富:数据结构丰富:支持 string、hash、set、sortedset、list 等数据结构。 缺点 Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的 IP 才能恢复。 主机宕机，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低了系统的可用性。 Redis 的主从复制采用全量复制，复制过程中主机会 fork 出一个子进程对内存做一份快照， 并将子进程的内存快照保存为文件发送给从机，这一过程需要确保主机有足够多的空余内存。若快照文件较大，对集群的服务能力会产生较大的影响，而且复制过程是在从机新加入 集群或者从机和主机网络断开重连时都会进行，也就是网络波动都会造成主机和从机间的一 次全量的数据复制，这对实际的系统运营造成了不小的麻烦。 Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 MongoDB 优点 弱一致性(最终一致)，更能保证用户的访问速度。 文档结构的存储方式，能够更便捷的获取数。 内置 GridFS，高效存储二进制大对象 (比如照片和视频)。 内置Sharding。提供基于Range的Auto Sharding机制：一个collection可按照记录的范围，分成若干个段，切分到不同的Shard上。 第三方支持丰富。(这是与其他的NoSQL相比，MongoDB也具有的优势)。 性能优越：在使用场合下，千万级别的文档对象，近10G的数据，对有索引的ID的查询不会比mysql慢，而对非索引字段的查询，则是全面胜出。 缺点 mongodb不支持事务操作。所以事务要求严格的系统（如果银行系统）肯定不能用它。 mongodb占用空间过大。 MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方。 MySQL和Redis对比MySQL 是持久化存储，存放在磁盘里面，检索的话，会涉及到一定的 IO，为了解决这个瓶颈，于是出现了缓存，比如现在用的最多的 memcached(简称mc)。首先，用户访问mc，如果未命中，就去访问 MySQL，之后像内存和硬盘一样，把数据复制到mc一部分。 Redis 和mc都是缓存，并且都是驻留在内存中运行的，这大大提升了高数据量web访问的访问速度。然而mc只是提供了简单的数据结构，比如 string存储；Redis却提供了大量的数据结构，比如string、list、set、hashset、sorted set这些，这使得用户方便了好多，毕竟封装了一层实用的功能，同时实现了同样的效果，当然用Redis而慢慢舍弃mc。 内存和硬盘的关系，硬盘放置主体数据用于持久化存储，而内存则是当前运行的那部分数据，CPU访问内存而不是磁盘，这大大提升了运行的速度，当然这是基于程序的局部化访问原理。 推理到 Redis + MySQL，它是内存+磁盘关系的一个映射，MySQL 放在磁盘，Redis放在内存，这样的话，web应用每次只访问Redis，如果没有找到的数据，才去访问 MySQL。 然而 Redis + MySQL 和内存+磁盘的用法最好是不同的。 前者是内存数据库，数据保存在内存中，当然速度快。 后者是关系型数据库，功能强大，数据访问也就慢。 像memcache，MongoDB，Redis，都属于No SQL系列。 FastJSON、Gson和Jackson性能对比（网摘）JSON序列化(Object =&gt; JSON)测试样本数量为100000个，为了保证每个类库在测试中都能处理同一个样本，先把样本Java对象保存在文件中。每个类库测试3次，每次循环测试10遍，去掉最快速度和最慢速度，对剩下的8遍求平均值作为最终的速，取3次测试中最好的平均速度作为最终的测试数据。 类库 样本数量 执行次数 最长时间(毫秒) 最短时间(毫秒) 平均时间(毫秒) FastJSON 100000 10 2291.22 1416.70 1454.93 Jackson 100000 10 1980.92 841.91 880.82 Gson 100000 10 2383.02 1469.08 1520.38 从测试数据可知，FastJSON和GsonJSON序列化的速度差不多，Jackson是最快的（用时Gson少大约600毫秒）。 JSON反序列化(JSON =&gt; Object)测试样本数量为100000个，为了保证每个类库在测试中都能处理同一个样本，先把样本JSON对象保存在文件中。每个类库测试3次，每次循环测试10遍，去掉最快速度和最慢速度，对剩下的8遍求平均值作为最终的速，取3次测试中最好的平均速度作为最终的测试数据。 类库 样本数量 执行次数 最长时间(毫秒) 最短时间(毫秒) 平均时间(毫秒) FastJSON 100000 10 7942.31 6340.55 6526.41 Jackson 100000 10 7957.22 6623.85 6815.41 Gson 100000 10 8235.15 7006.06 7364.75 从测试数据可知，三个类库在反序列化上性能比较接近，Gson稍微差一些。 总结把Java对象JSON序列化，Jackson速度最快，在测试中比Gson快接近50%，FastJSON和Gson速度接近。把JSON反序列化成Java对象，FastJSON、Jackson速度接近，Gson速度稍慢，不过差距很小。","categories":[{"name":"Java","slug":"Java","permalink":"https://maiyikai.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://maiyikai.github.io/tags/Java/"}]},{"title":"SpringBoot Druid(alibaba)--未完待续","slug":"1548754787","date":"2019-01-29T18:00:00.000Z","updated":"2019-10-12T12:21:09.263Z","comments":true,"path":"2019/01/30/1548754787/","link":"","permalink":"https://maiyikai.github.io/2019/01/30/1548754787/","excerpt":"Druid简介据我所知Druid目前有两个，两个项目虽然名字相同，但是作用却截然不同。它们分别为： 由美国广告技术公司MetaMarkets创建的一个分布式的支持实时分析的数据存储系统（Data Store）–Druid，开源于2012 年晚期 由阿里巴巴创建的一个数据库连接池的项目–Druid","text":"Druid简介据我所知Druid目前有两个，两个项目虽然名字相同，但是作用却截然不同。它们分别为： 由美国广告技术公司MetaMarkets创建的一个分布式的支持实时分析的数据存储系统（Data Store）–Druid，开源于2012 年晚期 由阿里巴巴创建的一个数据库连接池的项目–Druid 这里来我们只介绍由阿里巴巴开源的Druid项目 Druid–alibabaDruid是什么由阿alibaba在提供的介绍是：Druid是Java语言中最好的数据库连接池。Druid能够提供强大的监控和扩展功能。 关键词：数据库连接池、监控、扩展功能 Maven依赖Maven地址：http://central.maven.org/maven2/com/alibaba/druid/ 依赖配置： 123456&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid-version&#125;&lt;/version&gt;&lt;/dependency&gt; alibaba Druid源码开源地址:https://github.com/alibaba/druid Druid支持的数据库 数据库 支持状态 mysql 支持，大规模使用 oracle 支持，大规模使用 sqlserver 支持 postgres 支持 db2 支持 h2 支持 derby 支持 sqlite 支持 sybase 支持 Druid支持通过数据库URL自动识别驱动类 前缀 DriverCLass 描述信息 jdbc:odps com.aliyun.odps.jdbc.OdpsDriver jdbc:derby org.apache.derby.jdbc.EmbeddedDriver jdbc:mysql com.mysql.jdbc.Driver jdbc:oracle oracle.jdbc.driver.OracleDriver jdbc:microsoft com.microsoft.jdbc.sqlserver.SQLServerDriver jdbc:sybase:Tds com.sybase.jdbc2.jdbc.SybDriver jdbc:jtds net.sourceforge.jtds.jdbc.Driver jdbc:postgresql org.postgresql.Driver jdbc:fake com.alibaba.druid.mock.MockDriver jdbc:mock com.alibaba.druid.mock.MockDriver jdbc:hsqldb org.hsqldb.jdbcDriver jdbc:db2 COM.ibm.db2.jdbc.app.DB2Driver DB2的JDBC Driver十分混乱，这个匹配不一定对 jdbc:sqlite org.sqlite.JDBC jdbc:ingres com.ingres.jdbc.IngresDriver jdbc:h2 org.h2.Driver jdbc:mckoi com.mckoi.JDBCDriver jdbc:cloudscape COM.cloudscape.core.JDBCDriver jdbc:informix-sqli com.informix.jdbc.IfxDriver jdbc:timesten com.timesten.jdbc.TimesTenDriver jdbc:as400 com.ibm.as400.access.AS400JDBCDriver jdbc:sapdb com.sap.dbtech.jdbc.DriverSapDB jdbc:JSQLConnect com.jnetdirect.jsql.JSQLDriver jdbc:JTurbo com.newatlanta.jturbo.driver.Driver jdbc:firebirdsql org.firebirdsql.jdbc.FBDriver jdbc:interbase interbase.interclient.Driver jdbc:pointbase com.pointbase.jdbc.jdbcUniversalDriver jdbc:edbc ca.edbc.jdbc.EdbcDriver jdbc:mimer:multi1 com.mimer.jdbc.Driver SpringBoot Druid开发工具与包 idea SpringBoot 2.1.2.RELEASE MySQL Druid 1.1.10 fastjson 1.2.54 pom.xml依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.myk&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;druid&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-jdbc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.41&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.54&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657server: port: 8001mybatis: mapper-locations: classpath:mapper/*.xmlspring: datasource: druid: # 连接池的配置 url: jdbc:mysql://$&#123;mysql_host&#125;:$&#123;mysql_port&#125;/[database]?useUnicode=true&amp;characterEncoding=UTF8 # 数据库连接 username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver # 驱动类 initial-size: 10 # 初始化大小 max-active: 50 # 最大活跃数 min-idle: 5 # 最小空闲值.当空闲的连接数少于阀值时，连接池就会预申请去一些连接，以免洪峰来时来不及申请 max-wait: 20 # 最大等待 pool-prepared-statements: false #池的预编译，即PSCache max-pool-prepared-statement-per-connection-size: 10 # 每个连接上PSCache的最大值 validation-query: SELECT 1 FROM DUAL # 连接验证，mysql空闲八小时就会自动断开所有的连接，所以需要这一条语句保持 validation-query-timeout: 60000 # 连接超时时间 test-on-borrow: true # 检测池里连接的可用性 test-on-return: false # 连接归还到连接池时是否测试该连接 test-while-idle: true #当连接空闲时，是否执行连接测试. time-between-eviction-runs-millis: 30000 #指定空闲连接检查、废弃连接清理、空闲连接池大小调整之间的操作时间间隔 min-evictable-idle-time-millis: 30000 #指定一个空闲连接最少空闲多久后可被清除. filters: stat,slf4j # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&apos;wall&apos;用于防火墙 # 监控配置 # WebStatFilter配置 web-stat-filter: enabled: true # 是否启用StatFilter默认值true url-pattern: /* exclusions: &apos;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/* &apos; # 排除一些不必要的url，比如.js,/jslib/等等 session-stat-enable: true session-stat-max-count: 100 # 默认sessionStatMaxCount是1000个，你也可以按需要进行配置 profile-enable: true # druid 0.2.7版本开始支持profile，配置profileEnable能够监控单个url调用的sql列表 # StatViewServlet配置 stat-view-servlet: enabled: true #是否启用StatViewServlet默认值true url-pattern: /druid/* reset-enable: true login-username: maiyikai login-password: 123456 allow: 10.9.2.206 deny: 10.9.2.159 filter: stat: db-type: h2 log-slow-sql: true slow-sql-millis: 2000 wall: enabled: true db-type: h2 config: delete-allow: false drop-table-allow: false","categories":[{"name":"DataSource","slug":"DataSource","permalink":"https://maiyikai.github.io/categories/DataSource/"}],"tags":[{"name":"Druid","slug":"Druid","permalink":"https://maiyikai.github.io/tags/Druid/"},{"name":"DataSource","slug":"DataSource","permalink":"https://maiyikai.github.io/tags/DataSource/"}]},{"title":"Spring Boot DataSource配置","slug":"1548731189","date":"2019-01-29T11:00:00.000Z","updated":"2019-10-12T12:21:09.262Z","comments":true,"path":"2019/01/29/1548731189/","link":"","permalink":"https://maiyikai.github.io/2019/01/29/1548731189/","excerpt":"数据库基础知识理解 SQL组成： DML、DDL、DCL、TCL SQL组成名词解释： DML:数据操纵语言（Data Manipulation Language, DML）是SQL语言中，负责对数据库对象运行数据访问工作的指令集，操作语句：","text":"数据库基础知识理解 SQL组成： DML、DDL、DCL、TCL SQL组成名词解释： DML:数据操纵语言（Data Manipulation Language, DML）是SQL语言中，负责对数据库对象运行数据访问工作的指令集，操作语句： INSERT ：将数据插入到表或视图 DELETE ：从表或视图删除数据 SELECT ：从表或视图中获取数据 UPDATE ：更新表或视图中的数据 MERGE ： 对数据进行合并操作(插入/更新/删除) DDL:数据库模式定义语言DDL(Data Definition Language)，是用于描述数据库中要存储的现实世界实体的语言。操作语句： CREATE : 在数据库中创建新的数据对象 ALTER : 修改数据库中对象的数据结构 DROP : 删除数据库中的对象（可以删除数据表、索引、触发程序、条件约束以及数据表的权限等） DISABLE/ENABLE TRIGGER : 修改触发器的状态 UPDATE STATISTIC : 更新表/视图统计信息 TRUNCATE TABLE : 清空表中数据 COMMENT : 给数据对象添加注释 RENAME : 更改数据对象名称 DCL:DCL数据库控制语言不同于程序设计语言。是用来设置或更改数据库用户或角色权限的语句，操作语句： GRANT: 赋予用户某种控制权限 DENY REVOKE：取消用户某种控制权限 … … TCL:事务控制语言，管理事务,操作语句 COMMIT : 保存已完成事务动作结果 SAVEPOINT : 保存事务相关数据和状态用以可能的回滚操作 ROLLBACK : 恢复事务相关数据至上一次COMMIT操作之后 SET TRANSACTION : 设置事务选项 DataSource文件配置根据需求自定义配置，真实情况用不了这么多的配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192spring: dao: exceptiontranslation: enabled: # 是否开启PersistenceExceptionTranslationPostProcessor，默认为true datasource: abandon-when-percentage-full: # 设定超时被废弃的连接占到多少比例时要被关闭或上报 allow-pool-suspension: #使用Hikari pool时，是否允许连接池暂停，默认为: false alternate-username-allowed: #是否允许替代的用户名. auto-commit: #指定updates是否自动提交 catalog: #指定默认的catalog commit-on-return: #设置当连接被归还时，是否要提交所有还未完成的事务 connection-init-sql: #指定连接被创建，再被添加到连接池之前执行的sql. connection-init-sqls: #使用DBCP connection pool时，指定初始化时要执行的sql connection-properties: [key]: #在使用DBCP connection pool时指定要配置的属性 connection-test-query: #指定校验连接合法性执行的sql语句 connection-timeout: #指定连接的超时时间，毫秒单位. continue-on-error: #在初始化数据库时，遇到错误是否继续，默认false data: #指定Data (DML)脚本 data-source-class-name: #指定数据源的全限定名. data-source-jndi: #指定jndi的地址 data-source-properties: [key]: #使用Hikari connection pool时，指定要设置的属性 db-properties: #使用Tomcat connection pool，指定要设置的属性 default-auto-commit: #是否自动提交. default-catalog: #指定连接默认的catalog. default-read-only: #是否设置默认连接只读. default-transaction-isolation: #指定连接的事务的默认隔离级别. driver-class-name: #指定driver的类名，默认从jdbc url中自动探测. fair-queue: #是否采用FIFO返回连接. health-check-properties: [key]: #使用Hikari connection pool时，在心跳检查时传递的属性 idle-timeout: #指定连接多久没被使用时，被设置为空闲，默认为10ms ignore-exception-on-pre-load: #当初始化连接池时，是否忽略异常. init-sql: #当连接创建时，执行的sql initial-size: #指定启动连接池时，初始建立的连接数量 initialization-fail-fast: #当创建连接池时，没法创建指定最小连接数量是否抛异常 initialize: #指定初始化数据源，是否用data.sql来初始化，默认: true isolate-internal-queries: #指定内部查询是否要被隔离，默认为false jdbc-interceptors: #使用Tomcat connection pool时，指定jdbc拦截器，分号分隔 jdbc-url: #指定JDBC URL. jmx-enabled: #是否开启JMX，默认为: false jndi-name: #指定jndi的名称. leak-detection-threshold: #使用Hikari connection pool时，多少毫秒检测一次连接泄露. log-abandoned: #使用DBCP connection pool，是否追踪废弃statement或连接，默认为: false log-validation-errors: #当使用Tomcat connection pool是否打印校验错误. login-timeout: #指定连接数据库的超时时间. max-active: #指定连接池中最大的活跃连接数. max-age: #指定连接池中连接的最大年龄 max-idle: #指定连接池最大的空闲连接数量. max-lifetime: #指定连接池中连接的最大生存时间，毫秒单位. max-open-prepared-statements: #指定最大的打开的prepared statements数量. max-wait: #指定连接池等待连接返回的最大等待时间，毫秒单位. maximum-pool-size: #指定连接池最大的连接数，包括使用中的和空闲的连接. min-evictable-idle-time-millis: #指定一个空闲连接最少空闲多久后可被清除. min-idle: #指定必须保持连接的最小值(For DBCP and Tomcat connection pools) minimum-idle: #指定连接维护的最小空闲连接数，当使用HikariCP时指定. name: #指定数据源名. num-tests-per-eviction-run: #指定运行每个idle object evictor线程时的对象数量 password: #指定数据库密码. platform: #指定schema要使用的Platform(schema-$&#123;platform&#125;.sql)，默认为: all pool-name: #指定连接池名字. pool-prepared-statements: #指定是否池化statements. propagate-interrupt-state: #在等待连接时，如果线程被中断，是否传播中断状态. read-only: #当使用Hikari connection pool时，是否标记数据源只读 register-mbeans: #指定Hikari connection pool是否注册JMX MBeans. remove-abandoned: #指定当连接超过废弃超时时间时，是否立刻删除该连接. remove-abandoned-timeout: #指定连接应该被废弃的时间. rollback-on-return: #在归还连接时，是否回滚等待中的事务. schema: #指定Schema (DDL)脚本. separator: #指定初始化脚本的语句分隔符，默认: ; sql-script-encoding: #指定SQL scripts编码. suspect-timeout: #指定打印废弃连接前的超时时间. test-on-borrow: #当从连接池借用连接时，是否测试该连接. test-on-connect: #创建时，是否测试连接 test-on-return: #在连接归还到连接池时是否测试该连接. test-while-idle: #当连接空闲时，是否执行连接测试. time-between-eviction-runs-millis: #指定空闲连接检查、废弃连接清理、空闲连接池大小调整之间的操作时间间隔 transaction-isolation: #指定事务隔离级别，使用Hikari connection pool时指定 url: #指定JDBC URL. use-disposable-connection-facade: #是否对连接进行包装，防止连接关闭之后被使用. use-equals: #比较方法名时是否使用String.equals()替换==. use-lock: #是否对连接操作加锁 username: #指定数据库名. validation-interval: #指定多少ms执行一次连接校验. validation-query: #指定获取连接时连接校验的sql查询语句. validation-query-timeout: #指定连接校验查询的超时时间. validation-timeout: #设定连接校验的超时时间，当使用Hikari connection pool时指定 validator-class-name: #用来测试查询的validator全限定名. xa: data-source-class-name: #指定数据源的全限定名. properties: #指定传递给XA data source的属性 JPA文件配置JPA是Java Persistence API的简称，中文名Java持久层API，是JDK 5.0注解或XML描述对象－关系表的映射关系，并将运行期的实体对象持久化到数据库中。Sun引入新的JPA ORM规范出于两个原因：其一，简化现有Java EE和Java SE应用开发工作；其二，Sun希望整合ORM技术，实现天下归一。 123456789101112spring: jpa: database: #指定目标数据库. database-platform: #指定目标数据库的类型. generate-ddl: #是否在启动时初始化schema，默认为false hibernate: ddl-auto: #指定DDL mode (none, validate, update, create, create-drop). 当使用内嵌数据库时，默认是create-drop，否则为none. hibernate: naming-strategy: #指定命名策略. open-in-view: #是否注册OpenEntityManagerInViewInterceptor，绑定JPA EntityManager到请求线程中，默认为: true properties: #添加额外的属性到JPA provider. show-sql: #是否开启sql的log，默认为: false JTA文件配置JTA，即Java Transaction API，JTA允许应用程序执行分布式事务处理——在两个或多个网络计算机资源上访问并且更新数据。JDBC驱动程序的JTA支持极大地增强了数据访问能力。 12345678910111213141516171819202122232425262728spring: jta: allow-multiple-lrc: #是否允许 multiple LRC，默认为: false asynchronous2-pc: #指定两阶段提交是否可以异步，默认为: false background-recovery-interval: #指定多少分钟跑一次recovery process，默认为: 1 background-recovery-interval-seconds: #指定多久跑一次recovery process，默认: 60 current-node-only-recovery: #是否过滤掉其他非本JVM的recovery，默认为: true debug-zero-resource-transaction: #是否追踪没有使用指定资源的事务，默认为: false default-transaction-timeout: #设定默认的事务超时时间，默认为60 disable-jmx: #是否禁用jmx，默认为false enabled: #是否开启JTA support，默认为: true exception-analyzer: #设置指定的异常分析类 filter-log-status: #使用Bitronix Transaction Manager时，是否写mandatory logs，开启的话，可以节省磁盘空间，但是调试会复杂写，默认为false force-batching-enabled: #使用Bitronix Transaction Manager时，是否批量写磁盘，默认为true. forced-write-enabled: #使用Bitronix Transaction Manager时，是否强制写日志到磁盘，默认为true graceful-shutdown-interval: #当使用Bitronix Transaction Manager，指定shutdown时等待事务结束的时间，超过则中断，默认为60 jndi-transaction-synchronization-registry-name: #当使用Bitronix Transaction Manager时，在JNDI下得事务同步registry，默认为: java:comp/TransactionSynchronizationRegistry jndi-user-transaction-name: #指定在JNDI使用Bitronix Transaction Manager的名称，默认:java:comp/UserTransaction journal: #当使用Bitronix Transaction Manager，指定The journal是否disk还是null还是一个类的全限定名，默认disk log-dir: #ransaction logs directory. log-part1-filename: #指定The journal fragment文件1的名字，默认: btm1.tlog log-part2-filename: #指定The journal fragment文件2的名字，默认: btm2.tlog max-log-size-in-mb: #指定journal fragments大小的最大值. 默认: 2M resource-configuration-filename: #指定Bitronix Transaction Manager配置文件名. server-id: #指定Bitronix Transaction Manager实例的id. skip-corrupted-logs: #是否忽略corrupted log files文件，默认为false. transaction-manager-id: #指定Transaction manager的唯一标识. warn-about-zero-resource-transaction: #当使用Bitronix Transaction Manager时，是否对没有使用指定资源的事务进行警告，默认为: true 参考文章: 来自思否：@codecraft&gt;SpringBoot配置属性之DataSource","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/categories/SpringBoot/"}],"tags":[{"name":"DataSource","slug":"DataSource","permalink":"https://maiyikai.github.io/tags/DataSource/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://maiyikai.github.io/tags/SpringBoot/"}]},{"title":"Hexo添加搜索功能与百度分析","slug":"1548657877","date":"2019-01-28T14:45:00.000Z","updated":"2019-10-12T12:21:09.262Z","comments":true,"path":"2019/01/28/1548657877/","link":"","permalink":"https://maiyikai.github.io/2019/01/28/1548657877/","excerpt":"前两篇文章讲了搭建Hexo个人博客和主题的更换: 简单搭建Hexo Hexo添加hexo-theme-miho主题","text":"前两篇文章讲了搭建Hexo个人博客和主题的更换: 简单搭建Hexo Hexo添加hexo-theme-miho主题 但是主题里边有个搜索功能，一开始使用的时候，浏览器控制台总是报错，说content.json 404 懵了，主题切换的时候没注意，然后一直想怎么弄出来这个文件 现在，开始添加搜索功能，然后在加入百度分析 搜索功能自动生成一个很简单的方法，那就是让它在构建的时候自己生成”content.json”文件 打开 Git Bash Here 程序 输入命令 npm i -S hexo-generator-json-content 安装组件 在相对应的主题目录下的 “_config.yml” 文件下加入配置代码： 123456789101112131415161718192021222324252627282930313233343536# 自动生成content.json# https://github.com/alexbruno/hexo-generator-json-contentjsonContent: meta: true keywords: false # language name option dateFormat: undefined # format string pages: title: true slug: true date: true updated: true comments: true path: true link: true permalink: true excerpt: true keywords: true # but only if root keywords option language was set text: true raw: false content: false posts: title: true slug: true date: true updated: true comments: true path: true link: true permalink: true excerpt: true keywords: true # but only if root keywords option language was set text: true raw: false content: false categories: true tags: true 依次输入命令： 输入命令hexo clean清除缓存 输入命令hexo g构建 输入命令hexo d部署 在hexo目录下会生成public文件夹，在这个文件夹下就可以看到 “content.json” 这个文件了(可以打开，建议格式化之后在区查看) 部署好之后，可以在自己的hexo主页使用搜索功能了 手动添加手动添加呢，有点费时间，不过可以自定义条件 首先来看一下有哪些配置项 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; &quot;meta&quot;:&#123; &quot;title&quot;:&quot;&quot;, ## 博客标题 &quot;subtitle&quot;:&quot;&quot;, ## 博客子标题 &quot;description&quot;:&quot;&quot;, ## 博客描述 &quot;author&quot;:&quot;&quot;, ## 博客作者 &quot;url&quot;:&quot;&quot; ## 博客首页地址 &#125;, &quot;pages&quot;:[ ## 非博客博文的一些页面， 即不在hexo\\source\\_posts目录下的，但在hexo\\source下的md页面 &#123; &quot;title&quot;:&quot;&quot;, &quot;date&quot;:&quot;&quot;, ## 博客发布时间 &quot;updated&quot;:&quot;&quot;, ## 博客更新时间 &quot;comments&quot;:true, &quot;path&quot;:&quot;&quot;, ## 在当前首页地址下的路径 &quot;permalink&quot;:&quot;&quot;, ## 页面全路径 &quot;excerpt&quot;:&quot;&quot;, &quot;text&quot;:&quot;&quot; ## 页面内容 &#125; ], posts: [ ## 在hexo\\source\\_posts目录下的md文件生成的页面，即博文 &#123; &quot;title&quot;:&quot;&quot;, ## 博文标题 &quot;slug&quot;:&quot;&quot;, ## 博文md文件的文件名 &quot;date&quot;:&quot;&quot;, ## 时间 &quot;updated&quot;:&quot;&quot;, ## 更新时时间 &quot;comments&quot;:true, &quot;path&quot;:&quot;&quot;, ## 在当前首页地址下的路径 &quot;link&quot;:&quot;&quot;, &quot;permalink&quot;:&quot;&quot;, ## 页面全路径 &quot;excerpt&quot;:&quot;&quot;, ## 博文描述文字 &quot;text&quot;:&quot;&quot;, ## 博文内容 &quot;categories&quot;:[ ## 分类 &#123; &quot;name&quot;:&quot;Hexo&quot;, &quot;slug&quot;:&quot;Hexo&quot;, &quot;permalink&quot;:&quot;https://maiyikai.github.io/categories/Hexo/&quot; ## 分类文件路径 &#125; ], &quot;tags&quot;:[ ## 标签 &#123; &quot;name&quot;:&quot;Hexo&quot;, &quot;slug&quot;:&quot;Hexo&quot;, &quot;permalink&quot;:&quot;https://maiyikai.github.io/tags/Hexo/&quot; ## 便签文件的路径 &#125; ] &#125; ] &#125; 其实用不了这么多，简易版的： 1234567891011121314151617181920&#123; &quot;meta&quot;:&#123; &quot;title&quot;:&quot;&quot;, &quot;subtitle&quot;:null, &quot;description&quot;:&quot;&quot;, &quot;author&quot;:&quot;&quot;, &quot;url&quot;:&quot;&quot; &#125;, &quot;pages&quot;:[ ], &quot;posts&quot;:[ &#123; &quot;title&quot;:&quot;&quot;, &quot;comments&quot;:true, &quot;path&quot;:&quot;&quot;, &quot;text&quot;:&quot;Windows Hexo 博客 github Git GitHub&quot; ## 匹配一般只匹配title 和text的内容 &#125; ]&#125; 写好这个文件之后，把它放在hexo\\source文件夹下即可 依次输入命令： 输入命令hexo clean清除缓存 输入命令hexo g构建 输入命令hexo d部署 部署好之后，可以在自己的hexo主页使用搜索功能了 注：手动添加的方式一定要注意，添加或更新博文时，要同步更新 “content.json” 文件，否则会出问题 加入百度分析 百度分析注册/登陆地址：https://tongji.baidu.com/web/welcome/login 登陆之后，点击“代码管理&gt;&gt;代码获取”，看下图: 将这个key复制出来 修改主题目录下的 “_config.yml” 文件中的 baidu_analytics,如下图 依次输入命令： 输入命令hexo clean清除缓存 输入命令hexo g构建 输入命令hexo d部署 部署上去之后就可以了 参考文章: 来自简书：@minhow&gt;https://www.jianshu.com/p/eb9009f03178 来自Github:@alexbruno&gt;https://github.com/alexbruno/hexo-generator-json-content","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://maiyikai.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://maiyikai.github.io/tags/Hexo/"},{"name":"百度分析","slug":"百度分析","permalink":"https://maiyikai.github.io/tags/百度分析/"}]},{"title":"Hexo添加hexo-theme-miho主题","slug":"1548499757","date":"2019-01-27T10:00:00.000Z","updated":"2019-10-12T12:21:09.262Z","comments":true,"path":"2019/01/27/1548499757/","link":"","permalink":"https://maiyikai.github.io/2019/01/27/1548499757/","excerpt":"上一篇文章：简单构建Hexo，教您如何搭建一个简单的Hexo Blog https://maiyikai.github.io/2019/01/26/1548499728/","text":"上一篇文章：简单构建Hexo，教您如何搭建一个简单的Hexo Blog https://maiyikai.github.io/2019/01/26/1548499728/ 主题添加主题本文使用 hexo-theme-miho 主题 这里的主题不是我们自己写的，而是从Hexo官网主题clone过来的（开源） 复制该主题的 git 地址 打开程序 Git Bash Here ，进入博客目录下的themes目录下，clone git项目 cd themes 进入主题目录 git clone [gitAddr] [themes name] 克隆 git 项目到本地。[themes name]如果不填写，则会创建一个名为项目名的目录 输入命令ls查看是否 clone 成功绑定主题 Hexo主目录下的”_config.yml”文件部分解释 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: FlyingFish Blog ##页面名称，标签栏显示subtitle:description:keywords:author: maiyikai ##作者language:timezone:# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: https://maiyikai.github.io/ ##默认的地址，后边会有一些地方用到，请改为自己的博客地址root: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = &apos;&apos;)# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: &apos;&apos; per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: miho ##绑定主题，，在themes目录下的git主题的目录名称# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/maiyikai/maiyikai.github.io.git branch: master 主题的个性化配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144# hexo-theme-miho# https://github.com/wongminho/hexo-theme-miho# Favicon of your site | 网站iconfavicon: /pen_logo.ico# Header# Keywords of your site | 网站关键字keywords: maiyikai,maiyude,FlyingFish blog# Head headline | 头部标题header_title: FlyingFish&apos;s Blog# Head description | 头部描述header_description: 随笔记# Link to your logo | logo地址logo: images/logo2.png# Link to your banner_img | 首页banner图地址banner_img: images/banner.jpg# Menu setting | 菜单设置# name: Font Awesome icon | Font Awesome 图标# title: Home Title | 标题# url: //minhow.com Url, absolute or relative path | 链接，绝对或相对路径# target: true Whether to jump out | 是否跳出menu: home: title: Home url: / target: false archive: title: Archives url: /archives target: false user: title: About url: /about target: false# Social setting, use to display social information | 社交设置，用来展示社交信息# name: Font Awesome icon | Font Awesome 图标# title: Home Icon title | 图标标题# url: //minhow.com Url, absolute or relative path | 链接，绝对或相对路径# target: true Whether to jump out | 是否跳出social: home: title: maiyikai url: //maiyikai.github.io/ target: true github: title: Github url: //github.com/maiyikai/maiyikai.github.io target: true weibo: title: Weibo url: //weibo.com/maiyikai target: true# twitter:# title: Twitter# url: //twitter.com/huangminhow# target: true #qq: weixin: title: Weixin url: //maiyikai.github.io/images/user_weixin.jpg target: true #snapchat: #telegram: #envelope-o: #facebook: #google: #linkedin:# Content# Excerpt length | 摘录长度excerpt_length: 190# Excerpt link | 摘录链接excerpt_link: more&gt;&gt;# New window open link | 新窗口打开文章open_new_link: false# Article default cover picture，size：350*150 | 文章默认封面图，尺寸：350*150cover_picture: //maiyikai.github.io/images/banner.jpg# Open background particles | 开启背景粒子open_bg_particle: true# Open animation in homepage and head | 开启主页及头部动画open_animation: true# Article# Open toc | 是否开启toctoc: true# Open share | 是否开启分享share: true# Style customization | 样式定制style: # Main color tone | 主色调 main_color: &apos;#0cc&apos;# Reward | 打赏reward: # 0-close, 1-All articles are rewarding, 2-Article&apos;s md file has reward:true attribute, only reward # 0-关闭, 1-所有文章均有打赏, 2-文章的md文件里有reward:true属性，才有打赏 status: 1 # 标题 title: ~谢谢大爷~ # 微信，关闭设为 false wechat: images/wechat_code.jpg # 支付宝，关闭设为 false alipay: images/alipay_code.jpg# Comments | 评论 建议不使用 gitment,,网站证书过期了，使用很麻烦# 畅言，输入appid和appkeychangyan_appid: falsechangyan_appkey: false# 友言，输入idyouyan_id: false# disqusdisqus: false# gitment https://github.com/imsun/gitmentgitment: owner: false #你的 GitHub ID repo: &apos;&apos; #存储评论的 repo client_id: &apos;&apos; #client ID client_secret: &apos;&apos; #client secret# Analytics | 分析# 站长分析，输入站点idcnzz_analytics: false# 百度分析，输入key值baidu_analytics: false# google analytics | google分析google_analytics: false# Footer# Access statistics | “不蒜子”访问量统计access_counter: on: true site_uv: 总访客数： site_pv: 总访问量：# Copyright Information | 版权信息 ---不可更改，尊重他人的智力成果权copyright: 2018 MinHow 加入评论因为加入gitment有很多的问题，让我浪费了很多的时间，所以我改为了 “畅言” 进入畅言官网,注册一个账号 拉倒下边，点击 “立即免费获取畅言” 建站，随便点一个 配置畅言的基本设置 网上随便找一个小网站 进入备案号查询 复制需要的信息即可 提交审核 静静等待 上线畅言评论功能(部署之后才能使用) 获取appid和appkey 在畅言后台管理页面-》后台总览，往下拉就可以看到了 在主题themes目录下，编辑”_config.yml”文件，找到评论配置区域，粘贴信息即可 至此，在主题 hexo-theme-miho下，畅言就配置成功了 加入搜索页面中有个搜索功能，需要一个文件的支持 进入hexo主目录下的source文件夹 在当前文件夹下创建一个文件，文件名固定content.json 写入文件内容，即搜索用的关键字(使用的时候把注解去掉)1234567891011121314151617181920&#123; &quot;meta&quot;:&#123; &quot;title&quot;:&quot;FlyingFish Blog&quot;, ##博客名 &quot;subtitle&quot;:null, &quot;description&quot;:&quot;FlyingFish Blog,&quot;, &quot;author&quot;:&quot;maiyikai&quot;, &quot;url&quot;:&quot;https://maiyikai.github.io/&quot; ##博客地址 &#125;, &quot;pages&quot;:[ ], &quot;posts&quot;:[ &#123; &quot;title&quot;:&quot;简单构建Hexo&quot;, ##文章标题 &quot;comments&quot;:true, &quot;path&quot;:&quot;2019/01/26/1548499728/&quot;, ##文章路径，在博客地址下的路径 &quot;text&quot;:&quot;Windows Hexo 博客 github Git GitHub&quot; #关键字，也可以是文章的全部文本 &#125; ]&#125; 部署上线 依次输入命令： 输入命令hexo clean清除缓存 输入命令hexo g构建 输入命令hexo d部署 部署结束之后，可以使用您的地址访问了 效果应该是和本博客当前日期的版本是一致的","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://maiyikai.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://maiyikai.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://maiyikai.github.io/tags/Github/"},{"name":"Hexo Themes","slug":"Hexo-Themes","permalink":"https://maiyikai.github.io/tags/Hexo-Themes/"},{"name":"畅言","slug":"畅言","permalink":"https://maiyikai.github.io/tags/畅言/"}]},{"title":"简单搭建Hexo","slug":"1548499728","date":"2019-01-26T18:00:00.000Z","updated":"2019-10-12T12:21:09.261Z","comments":true,"path":"2019/01/27/1548499728/","link":"","permalink":"https://maiyikai.github.io/2019/01/27/1548499728/","excerpt":"作为一个名不希望受约束的程序员的我来说，拥有一个属于自己的博客平台是必要的","text":"作为一个名不希望受约束的程序员的我来说，拥有一个属于自己的博客平台是必要的不瞎说了,开始吧 环境准备此处使用Windows系统环境 Git仓库准备 在已是Git用户的前提下进行，如果您还不是Git用户，请点击此处进行注册 创建一个仓库，且对仓库命名有限制(eg:如果您想要您的仓库命名为”exmple”,但实际命名应在其后边加入”.github.io”。项目必须要遵守格式：账户名.github.io) 此处使用本博客仓库地址举例 本地环境准备 安装nodejs环境 从nodejs官方网站下载nodejs，并且安装 检查是否安装成功 win+R进入cmd命令行 输入命令 node -v 检查是否输入版本号 输入命令 npm -v 检查npm命令是否安装输出的结果应该和下图相似，说明成功安装： 安装Git 如果您还没有Git，可以点击此处进行下载安装并配置 检查是否安装成功 桌面右键查看菜单是否有这两个选项： Git GUI Here Git Bash Here 打开cmd命令行，输入命令git -version查看是否有有相应的版本号，如下图： 安装hexo客户端 打开Git Hash Here程序 输入命令 npm install hexo-cli -g安装Hexo插件(和网络有关，请耐心等待) 输入命令 hexo -v查看是否有相应的版本号输出即可（安装成功才有，和上边相似） 进入博客目录，输入命令hexo init初始化hexo环境，等待结束之后在目录下会存在几个目录 node_modules：是依赖包 public：存放的是生成的页面 scaffolds：命令生成文章等的模板 source：用命令创建的各种文章 themes：主题 _config.yml：整个博客的配置 db.json：source解析所得到的 package.json：项目所需模块项目的配置信息 Git授权管理 绑定当前用户：打开Git Bash Here程序，分别输入命令： git config -global user.name &quot;git用户名&quot; git config -global user.email &quot;git邮箱&quot; 生产授权密钥 输入命令cd ~/.ssh切换目录，密钥文件一定要保存在这个文件夹下（有可能被隐藏） 输入命令ssh-keygen -t rsa -C &quot;git邮箱&quot; 查看.ssh文件夹下是否存在以下两个文件： id_rsa私钥 id_rsa.pub公钥 在Github中添加公钥 登录Github，点击头像下的settings，添加ssh 新建一个new ssh key，将id_rsa.pub文件里的内容复制上去 测试ssh是否添加成功 输入命令ssh -T git@github.com测试添加ssh是否成功。如果看到”Hi“后面是你的用户名，就说明成功了 hexo本地测试及部署Github本地测试 使用程序Git Bash Here进入博客目录 输入命令hexo clean清除缓存 输入命令 hexo server使用默认端口开启服务也可以自己指定端口，输入hexo server -p &quot;port&quot;就可以使用自己的端口开启服务部署Github 进入博客目录，打开文件”_config.yml”，在文件最后添加 1234deploy: type: git #部署类型 repo: gitAddr #git的仓库地址 branch: master #分支 依次输入命令： 输入命令hexo clean清除缓存 输入命令hexo g构建 输入命令hexo d部署 部署结束之后，可以使用您的地址访问了，如：https://maiyikai.github.io 页面如下图相似，就是完成了 至此，简单的部署就完成了如有疑问，可以点击博客上方的微信图标，扫码添加小弟为好友私聊哦也可以在评论区评论","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://maiyikai.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://maiyikai.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://maiyikai.github.io/tags/Github/"}]}]}